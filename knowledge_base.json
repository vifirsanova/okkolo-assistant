[
    {
        "header": "python_1.pdf",
        "text": "Конспект: Числа и строки в Python.\nКонструкция IF.\nВ.И. Фирсанова\n24 сентября 2024\n1 Числа\n1.1 Комплексные числа: complex\nКомплексные числа представляются в виде a+bi, где a— вещественная\nчасть, а bi— мнимая часть, которая состоит из вещественного числа bи\nмнимой единицы i, равной√−1):\nx = 3+5j\ny = 5j\nprint ( type (x)) # <class ’complex ’>\nprint ( type (y)) # <class ’complex ’>\n1.2 Числа с плавающей точкой: float\nЧисла с плавающей точкой соответствуют вещественным числам, однако\nне являются ими из-за особенностей представления чисел в памяти вычис-\nлительного устройства:\na = 0.1 + 0.1 + 0.1\nb = 0.3\nprint (a == b) # False\nПочему 0.1 + 0.1 + 0.1не равно 0.3? Вещественные числа состоят из двух\nчастей – мантиссы и порядка. Мантисса – это целое число, например, 3.\nПорядок – это 10 в n-ной степени. Порядок задает количество знаков после\nзапятой. Чем больше памяти в битах выделяется на кодирование мантиссы\nи порядка, тем ближе наши числа к вещественным числам.\n1.3 Целые числа: int\nЦелые числа не имеют дробной части. Преобразование к целочисленному\nвиду дает округление:\n1\nx = 42\nprint ( type (x)) # <class ’int ’>\ny = 42.1\nprint (int (y)) # 42\n1.4 Булева переменная\nБулев тип данных имеет два значения: TrueиFalse. В Python этот тип\nследует из логических выражений, например and,or,not:\n3 == 3 and 3 == 3 # True\n3 == 3 or 3 == 2 # True\nnot isinstance (3, int ) # False\n4 not in [1, 2, 3] # True\n3 > 1 # True\n0 == 0 # True\n1 != 1 # False\n2 <= 1 # False\n2 Строки\nСтрока — это последовательность символов, и она является итерируемым\nобъектом:\n\"Hello , World \"\n’Hello , World ’\nСтрокимогутсодержатьспециальныесимволы,например,переносстро-\nки:\n’Hello , World \\nHello , World ’\nДля вывода строки используем функцию print():\nprint (’Hello , World ’) # Hello , World\n2.1 Форматирование строк: f-strings\nИспользование f-строк позволяет вставлять значения переменных в строку:\nname = \" John \"\nprint (f’Hello , { name }’) # Hello , John\n2\n2.2 Основные функции для работы со строками\n•Длина строки : Функция len()возвращает количество символов в\nстроке.\ns = \"Hello, World!\"\nprint(len(s)) # 13\n•Приведение к верхнему и нижнему регистру :\ns = \"Hello\"\nprint(s.upper()) # HELLO\nprint(s.lower()) # hello\n•Капитализация строки :\ns = \"hello\"\nprint(s.capitalize()) # Hello\n•Разбиение строки :\ns = \"one, two, three\"\nprint(s.split(’,’)) # [’one’, ’two’, ’three’]\n•Удаление пробелов :\ns = \" hello \"\nprint(s.strip()) # hello\n•Замена подстроки :\ns = \"this is an apple\"\nprint(s.replace(\"apple\", \"orange\")) # this is an orange\n•Регулярные выражения :\nimport re\ntext = \"Contact us at info@example.com\"\ncleaned_text = re.sub(r’\\S+@\\S+’, ’’, text)\nprint(cleaned_text) # Contact us at\n3\n3 Условные операторы\nУсловные операторы используются для выполнения кода в зависимости от\nистинности выражения:\nvar = 3\nif var == 3:\nvar += 1\nprint (var ) # 4\nОператор elseиспользуетсядляобработкислучая,когдаусловие ifложно:\nif var == 3:\nvar += 1\nelse :\nvar = 3\nОператор elifиспользуется для проверки дополнительных условий:\nif var == 3:\nvar += 1\nelif var == 4:\nvar += 2\nelse :\nvar = 3\n4\n",
        "timestamp": "2024-10-11T13:28:43.793711"
    },
    {
        "header": "HSE University",
        "text": "HSE University В старых версиях браузеров сайт может отображаться некорректно. Для оптимальной работы с сайтом рекомендуем воспользоваться современным браузером. We use cookies in order to improve the quality and usability of the HSE website. More information about the use of cookies is available here , and the regulations on processing personal data can be found here . By continuing to use the site, you hereby confirm that you have been informed of the use of cookies by the HSE website and agree with our rules for processing personal data. You may disable cookies in your browser settings. ✖ A A A ABC ABC ABC А А А А А Regular version of the site Divisions Faculty & Staff International Partnerships Academic Jobs Alumni University Life Campus in Moscow Moscow Nizhny Novgorod Saint Petersburg Perm For visually-impaired For visually-impaired User profile (HSE staff only) EN RU 中文 Campus in Moscow Moscow Nizhny Novgorod Saint Petersburg Perm For visually-impaired For visually-impaired User profile (HSE staff only) EN RU 中文 Admissions Admissions Degree Programmes Undergraduate Programmes Graduate Programmes Doctoral Programmes Online Programmes International Prep Year Learn Russian and complete a general preparatory course Scholarships Scholarships and Discounts HSE Global Scholarship Competition Open Doors: Russian Scholarship Project Tuition Fees Learn about programme costs Prepare to Apply Visa Support Mock Tests International Student Support International Student Life Find out what it’s like to study at HSE University and live in Moscow Programmes & Courses Programmes & Courses English-taught Degree Programmes Bachelor’s Master’s Online Programmes Get a Master's degree from HSE University online Short-term Programmes Semester in Moscow Russian Language Training Doing Business in Russia—Internship Summer Schools Exchange Programmes Summer University Enhance your knowledge with a wide selection of courses Research Research Divisions Research Centres International Laboratories About Research at HSE University Events Conferences Yasin International Academic Conference HSE University’s hallmark conference on economic and social development Publications Database of Publications HSE University Review IQ.hse.ru Research-based analysis by HSE experts International Support International Support Support For International Students For International Faculty Visa Support How to apply for a Russian visa Partnerships International Partnerships Double-degree Programmes Membership in Associations Student Exchange HSE University invites students from partner universities for one or two semesters About About Who We Are Facts and Figures HSE in Rankings Strategic Development HSE University History Staff Directory Faculties & Institutes Each of the four HSE campuses is made up of faculties, which manage degree programmes Buildings HSE Buildings Dormitories Student Housing Office HSE Libraries Nine libraries in HSE buildings and online access to e-resources Divisions Faculty & Staff International Partnerships Academic Jobs Alumni University Life International Admissions inter@hse.ru admissions.hse.ru/en +7 495 531-00-59 Map of HSE Buildings HSE, 1993–2024 Search Search Advanced search International Study Tour Experience: Discover HSE University Application deadline: October 13 XV International Conference on Higher Education (ICHE) October 23-25 Higher Education: Efficiency and Well-being Balance International Students from Across the World International students study on-campus and remotely A wide range of scholarships and comprehensive support prev next News All news Research & Expertise Try Your Hand at Predicting the 2024 Nobel Prize Winner in Economics The Faculty of Economic Sciences is launching its annual prediction contest. On October 14, the Nobel Committee will announce the winners of the Sveriges Riksbank Alfred Nobel Prize in Economic Sciences live on air. You have time to prepare and explore the landscape of contemporary economic thought. What topics and areas are considered particularly important and promising at the moment? Anyone can win. Research & Expertise HSE Experts Take Part in the First International Workshop on Technological Sustainability of BRICS On September 19–20, Skoltech hosted the First International Workshop on Technological Sustainability of BRICS: University-Industry Partnerships, organised jointly with HSE University Human Capital Multidisciplinary Research Center. The meeting was held as part of the BRICS working group on technology foresight and science and technology studies. Community ‘My Goal Was Not to Profit from the Corvids but to Develop Methods for People and Birds to Interact’ This summer, Rodion Mutsolgov from the Moscow Region enrolled in HSE University after developing a project to train birds of the corvid family to collect trash. His project was recognized as one of the best at the annual research project competition for applicants to HSE FCS. The HSE News Service interviewed the first-year student about his research discoveries and university experience. Research & Expertise Two HSE University Projects Receive Support for Commercialisation At the end of August 2024, the first projects to receive funding as part of the commercialisation support measure were announced. Starting in September 2024, two projects from the HSE Faculty of Computer Science—CardioLife and Melange—were selected for financial support to aid in the commercialisation of their products and services, enabling them to enter the market. Education ‘Communication with Native Speakers Allowed Me to Look at the Language from a Different Perspective’ Students from HSE University–Perm completed language courses in Tianjin, China. The programme included not only classes with native speakers, but also cultural events, accommodation in a dormitory at Tianjin University, and trips to local attractions. Research & Expertise ‘We Bring Together the Best Russian Scientists and AI Researchers at HSE University Site’ On October 25–26, 2024, HSE University’s AI and Digital Science Institute and the AI Research Centre hold the Fall into ML 2024 conference in Moscow. This year’s event will focus on the prospects in development of fundamental artificial intelligence, with SBER as its conference title partner. Education HSE Tops the Ranking of Universities Leading in Technology Entrepreneurship HSE University has taken a leading position in the university ranking prepared by the 'Expert' analytical centre. The ‘Techpred-50’ ranking evaluates the success of educational institutions in training founders of technology startups over the period from 2014 to 2023. HSE University has entered the Top-3, alongside MIPT and Moscow State University. Research & Expertise Neural Network for Assessing English Language Proficiency Developed at HSE University The AI Lingua Neural Network has been collaboratively developed by the HSE University’s AI Research Centre, School of Foreign Languages, and online campus. The model has been trained on thousands of expert assessments of both oral and written texts. The system evaluates an individual's ability to communicate in English verbally and in writing. Education Graduate of HSE University in St Petersburg Receives Award at ‘Chinese Bridge’ Competition in Beijing In September 2024, Anastasia Usyk, a graduate of the Bachelor’s Programme in Asian and African Studies at HSE–St Petersburg, participated in the final round of the ‘Chinese Bridge’ Language Competition, where she won the first prize and received the Audience Award and the Award for Most Outstanding Performance. She spoke about her studies and future plans in an interview with HSE News Service. Show more Events All events 11 October Louis Vervoort to speak on 'Gettier's Problem and Quine's Epistemic Holism: A Unified Account' Starts at 18:30 null Online 14 October ANR-Lab Seminar 'Patterns of Structuring Classmate Preferences in Ethnically Mixed Classes' Starts at 15:00 null Online 23 25 October XV International Conference on Higher Education (ICHE) 25 26 October Sixth ICEF Conference on Applied Economics 25 26 October Conference on Machine Learning 'Fall into ML 2024' 28 October 9 December Course 'From a Research Idea to a Paper Draft' Online Show more Subscribe HSE University 360° Show more Alumni Careers, loyalty programmes, and mentorship International Prep Year Study Russian and complete a general preparatory course Young Scientists Early-career researchers talk about their work at HSE University University Buildings Campuses, dorms, accommodation options Careers at HSE Universty International faculty recruitment University Life News and events for HSE students and staff HSE Dormitories HSE Library On-campus libraries and remote access Pokrovka One of the most modern university complexes in Russia HSE University Strategic Development HSE International Olympiad INTO HSE: your chance to get a discount or study for free at HSE University Russian Longitudinal Monitoring Survey – HSE Nationally representative surveys since 1992 HSE Library e-resources Get access to databases and periodicals Summer Schools Joint Economic and Social Data Archive Free access to results of empirical research in social sciences Life in Moscow HSE University recommends International Student Support IQ: Commentary by HSE Experts Research and education International Faculty Support Sports at HSE University Sports clubs, gyms, contests Student Voices HSE is a school that will exceed your expectations. If you are accepted and want to pursue an academic career, do your best and study hard. High grades will open up many opportunities for you here, such as teaching and research assistant positions. Bai Xinyi (China) , Master’s programme in Economics and Economic Policy , with a focus on Behavioural Economics During my first year of the Master’s degree, I had the opportunity to meet professors and students with a highly competitive level in regional studies, Asian studies, and international relations. The programme is multidisciplinary, giving the opportunity, through courses and elective subjects, to focus your studies and converge them with your academic interests Sergio Terrón (Spain) , Master's programme in Socioeconomic and Political Development of Modern Asia I feel excited to delve into researching political regimes and conflicts among countries. I aim to achieve my goal of addressing pressing issues such as poverty, inequality, education, healthcare, and human rights violations through policy advocacy. Tajrin Rahman Tisha (Bangladesh) , Master's programme in Politics, Economics, Philosophy I researched online the best master's programmes in Russia for international students, and HSE's programmes stood out, so I decided to study here. I enjoyed my programme and had the opportunity to meet people from all over the world. Domingo Garcia (Mexico) , Master's programme in International Management I’ve already learnt much more than I expected. Everything we study is done in great detail. You do not stop after learning a theory: you need to understand how this theory is linked to the model and the empirics. Back in Ghana, I had heard about racism in Russia. However, since arriving, I’ve never felt any discrimination. Russians are very nice. What I’ve seen is totally different from what was portrayed in the media. Roosevelt Ogah (Ghana) , Master’s programme in Economics and Economic Policy HSE University in Numbers 95 % of alumni find employment within six months of graduation > 55,000 students and doctoral students > 400 international partners >5,000 instructors and researchers 47 centres of excellence prev next Contacts International Admissions inter@hse.ru admissions.hse.ru/en +7 495 531-00-59 Map of HSE Buildings International Students Support istudents.support@hse.ru istudents.hse.ru/en +7 495 772-95-90, ext. 27661 Emergency hotline: +7 (985) 040-13-55 Main campus : 11 Pokrovsky Bulvar International Faculty Recruitment iri@hse.ru iri.hse.ru +7 495 772-95-90, ext. 12669 International Faculty Support ifaculty.support@hse.ru ifaculty.hse.ru PR Office press@hse.ru pr.hse.ru/en/ +7 495 772 9567 About About Key Figures & Facts Sustainability at HSE University Faculties & Departments International Partnerships Faculty & Staff HSE Buildings Public Enquiries Studies Admissions Programme Catalogue Undergraduate Graduate Exchange Programmes Summer University Summer Schools Semester in Moscow Business Internship Research International Laboratories Research Centres Research Projects Monitoring Studies Conferences & Seminars Academic Jobs XXIV Yasin (April) International Academic Conference on Economic and Social Development Media & Resources Publications by staff HSE Journals Publishing House iq.hse.ru: commentary by HSE experts Library Economic & Social Data Archive Video ©  HSE, 1993–2024 Contacts Copyright Privacy Policy Site Map HSE Sans and HSE Slab fonts developed by the HSE Art and Design School Edit",
        "timestamp": "2024-10-11T13:28:58.338263"
    },
    {
        "header": "Untitled.txt",
        "text": "﻿INTRODUCTION\nIn recent years, the remarkable Natural Language Processing (NLP) advancements have been driven by the development of Large Language Models (LLMs). For example, models derived from GPT (Ouyang et al., 2022: 27733), and multi-task conversational agents, such as Mistral (Jiang et al., 2023: 2), are state-of-the-art across many NLP tasks. LLMs are probabilistic agents for causal language modeling. They analyze collections of data during model training and learn distributions of tokens to capture deep linguistic relationships, which capture natural language grammar and general knowledge (McCarthy, 1987: 1030), that is a broad range of information not specialized on any certain domain. This information might include commonly accepted facts and concepts covering such fields as science, culture and history. Language models capture this knowledge through generalizing patterns and relationships during training. For example, scientific information is often described with special terms, such as professional terminology. Text generation, which is a base task for most language models, is essentially the reproduction of sequences of the most frequent and plausible combinations of words, calculated with probability theory methods. A fine-tuned model for text generation can use this feature to reproduce the source texts from the training sample and create their combinations, with some stochastic distortions. As a result, a language model can convey knowledge from these texts. This process is closely related to process called meta-learning, that is a model’s ability to learn strategies to solve novel tasks without being explicitly trained on them, based on extracted patterns and relationships (Schmidhuber, 1987: 5).\nThe LLMs’ ability to capture deep linguistic relationships allows using them in conversational agents, such as OpenAI ChatGPT or Google Gemini. Despite the LLMs’ superior performance across numerous NLP tasks, the models do not store any information explicitly. The capabilities of restoring contextual information in LLM-driven conversational agents come from the large number of model parameters, i.e. the number of features representing deep relationship across the tokens. Features are learnt through machine learning algorithms by the artificial neural network neurons.\nFor example, in GPT 3.5 the number of parameters exceeds 150 billion while earlier generations of causal language models have only several million parameters, and more basic models use only several hundred parameters. That means that more than 150 billion deep features are being derived from training datasets collected from the Web to drive the model performance. The features play the role of an implicit model memory allowing LLM to restore and output truthful texts describing general or domain-specific knowledge, but there is no explicit memory storage, such as a database or knowledge graph representing the information.\nPerplexity (Jelinek et al., 1977: S63) is a commonly used metric score in language modeling. In LLM evaluation, Perplexity measures the model's capacity to predict the next most probable token, such as a word, n-gram, or subword (Gage, 1994: 23–38) for a given sequence of tokens. Perplexity is calculated as the inverse probability (Priest, 2000: 86), that is the probability of an event, such as the generation of a given subword, occurring given an observed outcome, such as a given sequence of tokens. In simple terms, Perplexity calculates the probability of an event occurring backward from the observed data to derive the values ​​of the evaluation metrics, which is why a lower Perplexity score indicates high predicting capacity. Low Perplexity scores are associated with an ability to understand the language structure since the ability to generate sequences implies modeling cohesion and coherence, which is impossible without identifying patterns of linguistic structure (Morris, Hirst, 1991: 21, 25-26). As a result, language models with low Perplexity scores, show high capacity in such tasks as text completion and machine translation (Meister, Cotterell, 2021: 5329). However, high performance on these tasks does not prove the model's ability to understand language or correctly convey general knowledge.\nPerplexity measures the probability distribution of word sequences, focusing on syntactic and local contextual accuracy, but does not take into account factual correctness or context understanding. As mentioned, most LLMs lack explicit information storage. Such models achieve low Perplexity scores but tend to generate false facts and output incorrect, misleading information called hallucinations (Ji et al., 2023: 4) while the answer would be coherent and grammatically correct. From the point of view of psychology, a coherent text containing false information would likely be interpreted as truthful, raising ethical concerns regarding the industrial use of LLMs. Evaluation metrics that assess the factual accuracy of LLMs include Precision and Recall, human judgment, and specialized benchmarks, such as Benchmarking Information Retrieval (BEIR) (Thakur et al. 2021: 1-2) and Massive Multitask Language Understanding (MMLU) (Hendrycks et al. 2021: 2) datasets, that test models on tasks such as question answering, fact-checking, or real-world information retrieval. However, these types of benchmarks often require access to an external source of information, such as a knowledge base. Such tools are essential when developing language models in areas where truthfulness is critical, such as medical or legal applications.\nOne of the solutions is Retrieval-Augmented Generation (RAG) (Zhang et al., 2023: 2). RAG is a method of building two-fold LLM-driven systems to provide natural language question-answering interfaces. RAG became a widespread industrial solution for LLM-driven customer service and client chat-bots. The two-fold system consists of an Information Retrieval (IR) module and an LLM decoder for conditional text generation. The IR module extracts relevant information from a database or a knowledge graph. The decoder uses extracted information to generate coherent text based on the retrieved facts.\nRAG makes LLMs’ outputs more controllable and predictable, although it does not solve the problem of false information generation completely. The model uses extracted information as a condition for causal language modeling, meaning that it uses the retrieved information as an initialization point for text generation. The model generates an answer by predicting a plausible continuation for the user prompt given extracted data, but it does not process given data explicitly and finely enough to ensure control and security.\nAnother problem is data breaches and plagiarism generation caused by LLMs’ memorization capabilities. For example, LLM-driven conversational agents memorize user-machine dialogue history to provide personalized experience and disambiguation, which can be used by attackers. Combining the advantages of decentralized security algorithms (Luo et al. 2023: 4) with proper personal data encoding can solve this problem.\nThis paper aims to provide a three-in-one approach that combines the power of LLMs with RAG advantages and decentralized systems security solutions. There is a research gap in LLM combinations studies while stacking several different models might become a simple solution that solves ethical problems algorithmically and allows for decreasing both computational costs and training data volume minimum requirements.\nCombining three state-of-the-art technologies in one novel solution might result in an energy-efficient LLM-driven framework that is protected from data breaches and false information generation. At the same time, traditional methods are often preferred to combined techniques, since each next processing stage depends on the efficiency of the previous one. The study goal is to explore whether the cautious approach toward complex LLM-driven frameworks is justified by assessing their reliability compared to traditional RAG on an example of the development of a custom LLM-based system designed for inclusive education needs. The study states the following research hypotheses:\n    • Hypothesis 1: Advanced LLM-driven frameworks consisting of several modules, such as an information retrieval module, privacy and security mechanisms, and text generation engine, that are built to solve specific problems or serve specific domains, offer better reliability and text generation quality than traditional RAG pipelines, such as Retrieval-Augmented Language Model (REALM) (Guu et al. 2020).\n    • Hypothesis 2: RAG methods, which have already proven their effectiveness, are more reliable than complex methods fine-tuned to solve specific problems or serve specific domains.\nTo test the research hypotheses, the research will focus on the following tasks:\n    • Define the specific use cases to deploy, test, and compare different LLM-driven systems.\n    • Describe different frameworks for testing two hypotheses.\n    • Implement and fine-tune LLM-driven systems tailored for the defined use cases.\n    • Define evaluation metrics to assess system performance in terms of reliability, efficiency, and safety.\n    • Compare the systems in a specific application based on the defined use cases.\nThis study involves the development and use of the following datasets:\n    • Training and test data: The models will be trained and tested using a knowledge base constructed as a Resource Description Framework (RDF) (Powers, 2003: 19) graph containing detailed information about inclusive education. This knowledge base provides the model with content related to education policies, practices, and support mechanisms.\n    • Model evaluation data: Evaluation will be conducted using a synthetic dataset designed for linguistic experiments. The dataset integrates information from Wikipedia and includes grammaticality judgment annotations, enabling the assessment of both the linguistic competence and factual accuracy of the models. This dataset allows for assessing the model's ability to differentiate between grammatical and non-grammatical sentences and its proficiency in providing general knowledge.\nThe efficiency and reliability of the LLM-driven frameworks are assessed through a combination of performance metrics and user feedback. Efficiency is measured by the response time, Perplexity, and the F-Score (Van Rijsbergen, 1979: 134) obtained on information retrieval from the RDF graph. Reliability is evaluated based on the model's consistency in providing correct and contextually appropriate answers using human feedback. The evaluation method uses two distinct datasets. First, the RDF knowledge base tests the model's ability to provide structured information about inclusive education. Second, the synthetic dataset tests the model's linguistic competence by assessing its ability to judge grammatical and non-grammatical sentences. The linguistic competence dataset is also used for the human evaluation experiment.\nThe study highlights the development of a dialogue system for inclusive education. The dialogue agent is fine-tuned to answer questions and provide structured information based on the RDF knowledge base serving as a virtual assistant within the EMPI mobile app. For more detailed information about the EMPI app, refer to vifirsanova.github.io/empi-web. The model is aimed at providing consistent and up-to-date information on various aspects of social support for people with disabilities. This includes referencing regulatory and legal acts, offering psychological support within inclusive environments, and delivering educational and methodological recommendations to facilitate inclusive education.\nThe study novelty includes the following contributions:\n    • Novel LLM-driven framework: The study proposes the integration of Retrieval-Augmented Generation (RAG) with blockchain technology and a set of LLM guardrails for enhanced security and reliability.\n    • Evaluation method: The study proposes a novel approach to assess LLM linguistic competence by measuring the model's ability to recognize grammatical and non-grammatical sentences, alongside evaluating its general and domain-specific knowledge on the example of inclusive educational material.\n    • Datasets: The study utilizes two novel distinct datasets: an RDF graph focused on inclusive education and a synthetic dataset tailored for linguistic grammaticality judgments..\n\nRELATED WORK\nThe history of Natural Language Processing (NLP) goes back to the first dialogue model ELIZA developed in the 1960s (Weizenbaum, McCarthy, 1977: 68). ELIZA was the first conversational agent that mimicked a psychotherapist by rephrasing user questions. The model based on a simple pattern-matching algorithm and a primitive language parser took user input and searched for tokens suitable for paraphrasing. The model inserted the tokens into predefined templates to output the answer. This early NLP technology defined two stages of any natural language interface. The first stage is input analysis augmented by information extraction, e.g. searching for patterns or data extraction. The second stage is output compilation or text generation. This high-level architectural structure is noticeable in every generation of NLP models, from rule-based techniques and statistical sequence-to-sequence methods to deep neural networks, including Transformer-based large language models (LLMs).\nModern dialogue systems often incorporate databases (Gao et al., 2018: 30) with various structures to implement the information extraction stage, or they use the implicit model memory capability known as meta-learning (Schmidhuber, 1987: 5). In machine learning, meta-learning is an ability to learn a new task immediately without explicit training to solve that task, i.e. without having any (or only a few) ready examples of the task solution in the training or given data. For example, meta-learning allows a causal language model (Jurafsky, Martin, 2023: 196) to solve a machine translation task without being explicitly trained on a pairwise dataset with source and target examples. Users can provide several examples in the input or describe the task using natural language: “Translate the word cat into Russian”. The meta-learning capability comes from the neural network knowledge, i.e. features encoded in the model neurons. Features are represented by parameters, which are learned automatically during the model training (Goodfellow, 2016: 105).\nTransformer-based models (Vaswani et al., 2017: 4) have robust meta-learning capacities due to their ability to learn deep relationships across the input data from the Attention mechanism. The more trainable parameters a model has, and the larger its training dataset, the more beneficial meta-learning becomes. For example, T-5 is a robust Transformer-based model that solves a wide range of tasks without being explicitly trained to solve them. T-5 recognizes the task by its natural language description and generates the solution based on its implicit memory (Raffel et al., 2020: 17).\nThe LLM capacity towards user intention recognition was developed in such model architectures as InstructGPT (Ouyang et al., 2022: 27733) or Mistral (Jiang et al., 2023: 2). Such models use the power of Reinforcement Learning from Human Feedback (RLHF) (Christiano et al., 2017: 3) to build a policy, i.e. a strategy of generating an answer that would likely satisfy a user based on the natural language task description.\nCausal language models fine-tuned to align with user intent based on human feedback is a robust solution, which, nevertheless, has notable drawbacks. Firstly, one significant issue is artificial intelligence hallucinations, a phenomenon of generating incorrect or misleading content. Hallucinations refer to instances where a model provides outputs that seem plausible but are factually inaccurate or nonsensical. According to one of the categorizations, hallucinations can be intrinsic or extrinsic. Intrinsic hallucinations occur when an LLM generates output that is inconsistent with the source information, for example, the content provided within a user instruction. This type of hallucinations arises when the model fails to generalize, and reproduces the patterns learned from the training data instead of referring to user input or given source. Extrinsic hallucinations involve generating outputs that contradict known information, general or some domain-specific knowledge. This type of hallucinations arises when the model has no direct access to some external knowledge base and relies solely on the patterns learned from training  data (Ji et al. 2024: 4). Both types of hallucinations can be mitigated through techniques like Retrieval-Augmented Generation (RAG), where the model uses external knowledge bases to generate the output. The RAG method reduces intrinsic hallucinations by providing the ability to compare source information with generated text using information extraction and vector similarity search. This approach also reduces extrinsic hallucination by referencing external data during the text generation (Zhang et al., 2023: 2). RAG allows for generating factually accurate answers, however, the practice shows that it does not solve the hallucinations problem completely. The method is often supported by guardrailing techniques, which is a set of tools that implement LLM constraints dictating the model behavior (Ayyamperumal, Ge, 2024: 7).\nSecondly, the large size of LLMs often limits their deployment in low-resource environments, such as mobile devices. To address this, techniques like GGML/GGUF for optimizing memory usage, as well as methods like Low-Rank Adaptation (LoRA) and Quantized LoRA (QLoRA), have been developed to enable small and efficient models suitable for constrained computational conditions. GGML and GGUF are file formats based on C++ library designed to run machine learning models on low-resource hardware, such as personal computers, mobile devices, and other environments with limited processing power through quantization, that is converting the numbers representing a model's parameters (such as weights and activations matricies) to lower precision values (Gerganov, 2024). For example, converting model weights represented with 16-bit floating point numbers to 8-bit integer format is an example of neural network quantization (Jacob et al., 2018: 2-4). Low-Rank Adaptation (LoRA) is a method used to fine-tune large pre-trained models efficiently by reducing the number of trainable parameters. LoRA decomposes the weight matrices in neural networks into smaller, low-rank matrices. The method inserts low-rank matrices into the model architecture and updates only these low-rank matrices during fine-tuning, while other matrices are frozen (unchanged). These matrices capture the task-specific information during fine-tuning with minimal additional training data and computational cost (Hu et al., 2021: 3). Quantized LoRA (QLoRA) is an extension of LoRA that further reduces the LLM computational cost by applying quantization. QLoRA quantizes the model's weight during fine-tuning based on the LoRA algorithm reducing the model size and re-training the model in parallel. QLoRA enables the deployment of large language models on devices with extremely limited resources, such as mobile devices (Dettmers et al., 2024: 3).\nThirdly, LLMs face cybersecurity risks, such as prompt injections (Choi et al., 2022: 2), where attackers manipulate model behavior through crafted input instructions. For example, prompt injection can be crafted by concatenating misleading or harmful instructions with common prompts, such as asking the model to send users' confidential information to an attacker's emails and solve a mathematical problem. The mathematical problem is a common and safe prompt, which an attacker use to mask the malicious instruction to send confidential information. The masking allows to bypass security filters and cause data leakage. To mitigate the risks posed by prompt injections, developers can implement guardrails for input sanitization, that is, pre-processing and filtering potentially malicious prompts, detecting suspicious patterns in input queries, as well as checking the output content according to ethical guidelines. Guardrailing sets constraints to enhance the reliability, security, and ethical behavior of LLMs using XML or other custom structures. NVIDIA Nemo or Guardrails AI are widespread implementations for these strategies (Ayyamperumal, Ge, 2024: 5, 7).\nLLM security can be solved by incorporating a decentralized approach into the NLP architecture. Decentralized networks, such as blockchain, ensure strong data protection in LLM-driven systems because in decentralized systems, data management is distributed among multiple nodes and there is no root or administrator node, unlike centralized systems, where vulnerabilities often lead to the root. Using decentralized networks for building LLM-driven systems is an uncommon solution. Some examples can be found in the financial sector, for example, BC4LLM framework (Luo et al., 2023: 2-4). Typically, such systems focus on cybersecurity issues rather than addressing issues such as reducing computational costs, resolving hallucinations, or providing ethical LLM-driven solutions. This study proposes a solution that will shift the focus from using decentralized networks from developing financial and commercial solutions to solving the problems of non-profit organizations, in the social sector.\nThe paper presents a novel LLM-driven framework, the Graph-Based Block-to-Block Generation (G3BG), that combines RAG with secure decentralized networks, uses guardrails to control LLM behavior and is evaluated using human feedback (Firsanova, 2021: 58) and linguistic knowledge. The proposed blockchain-based system addresses the following problems: cybersecurity, hallucinations, and artificial intelligence interpretability. To address the cybersecurity issues, the framework applies blockchain and guardrails. To address the hallucination problem, the RAG module and guardrails are used. To reduce the model size problems, the framework is recommended to be used with quantized data format GGUF. For the interpretability, the framework stores the information in sequential blocks containing conditions used to generate a response to a prompt, a current prompt, a history of human-machine interaction, information used by the RAG module, and user data for system personalization. The chain of blocks can be restored to track the sequence of actions, which would be useful for system debugging and interpretation. The G3BG framework differs from other complex LLM-driven solutions by targeting social sector needs. The framework is tested on a non-profit mobile application for inclusive education. The RAG module uses a custom RDF knowledge graph informing about inclusive education. The guardrails are set by a custom XML document. The experiments with LLMs are performed using GGUF format and an open-source C++ library provided by G. Gerganov, LM Studio software, Google Cloud services and OpenAI API.\nDATA\nThe study presents a novel RDF knowledge base for training and test data. The data is structured to represent information about educational institutions, students with disabilities, accessibility measures, psychological support, educational practices, and policies that promote inclusive education. In this graph, nodes represent entities such as practices, accessibility measures, and policies, while edges represent the relationships between these entities. Figure 1 illustrates the structure of the graph. The graph is RDF-serializable, and it is stored at github.com/vifirsanova/empi/KB. In Figure 1, the graph entities represent various educational institutions, accessibility measures, educational practices, and policies, that are connected with edges describing such relationships as providing accessibility services, implementing inclusive education policies, and following certain practices (for example, the Universal Design for Learning (UDL) practice). Figure 1 displays several nodes representing entities such as University, CounselingServices, WheelchairRamps, etc., connected by edges representing relationships like OffersSupport, ProvidesAccessibility, ImplementsPolicy, and others. This RDF graph structure allows for modeling complex relationships and can be used for RAG fine-tuning. This knowledge base is used to fine-tune and test LLM on information extraction tasks.\nThe data was collected through a custom crowdsourcing platform. Figure 2 shows the crowdsourcing platform user interface. Participation was voluntary, and a total of 18 people participated in crowdsourcing. The participants were representatives of the educational environment, for example, educators of schools and higher education institutions. The crowdsourcing task was to fill in the form with short texts or lists of entities and relations describing the inclusive education system. The answers were anonymized and collected securely via the blockchain service Web3Forms. Additionally, such documents as Federal Laws, Official websites of State Enterprises, and accessibility guidelines, such as W3C Accessibility Guidelines (WCAG) 3.0 were analyzed and used to form the RDF knowledge base.\nThe study also presents a novel tabular dataset used for the model evaluation. The dataset size is 5.3 GB. Table 1 shows the dataset sample. The full dataset is available at huggingface.co/datasets/missvector/multi-wiki-grammar. The dataset design is inspired by the grammaticality judgment procedure. The dataset is multilingual. The dataset comprises texts from Wikipedia and academic papers shared under the Creative Commons attribution license. The text preparation for this dataset included the following steps: Unicode normalization using Normalization Form KD (NFKD), artifact removal (for example, certain Wikipedia-specific artifacts, such as soft hyphens (\\xad) and accents, are removed, as well as bracketed content), filtering sentences shorter than 50 characters and longer than 100 characters. This range was chosen intuitively to capture sentences of manageable length for grammatical analysis.\nThe data was annotated synthetically after the sentence-level text segmentation. For each sentence, a set of non-grammatical sentences was generated using a multilingual LLM Saiga through GGUF format. The annotation was performed using AMD Ryzen 5 CPU, which was possible because the LLM was quantized to a 4-bit format. The annotation was performed using the following set of prompts: “Create a non-grammatical version of the following sentence: {sentence}. Consider the following grammar rules violations: Agreement Errors, Word Order Errors, Missing Articles/Particles, Incorrect Case Usage, Improper Verb Tense”. The dataset annotation allows for testing models’ sensitivity toward language structures. The limitation of this dataset is that it is fully synthetic. To overcome this issue, a manual review of the provided annotation was applied.\nMETHOD\nThe proposed method is tailored to the development of an inclusive mobile application development. The app was presented at ACM Web Conference in 2023 (Firsanova, 2023: 556). Figure 3 shows the framework diagram. The proposed G3BG model consists of block forming module, decentralized network, guardrails, an RDF knowledge base for RAG, an answer generation module, and a validation module that presents the response to the user. The process begins with a user inputting a prompt or query. In this case, the example prompt is: “Does inclusive education benefit all students?” The block forming module creates a new block with the following components:\n    • User Information: Details about the user for providing a personalized user experience, such as user age, preferred tone-of-voice, and accessibility settings. \n    • Log: A record of the user-machine interaction history.\n    • Tokens: Tokenized user input.\nThe gathered information organized into a block is distributed across a decentralized network, where multiple nodes interact with each other (in Figure 3, the nodes are represented by computers). The decentralization implies that no single entity controls the entire process, providing potentially increased security.\nThe information is stored in blocks. Each block uses JSON structure. The block stores a unique block identifier, hash encoding for providing security, human-machine interaction timestamp, user personalization information, log, set of prompt tokens, and placeholders for the answer generation result, RAG extraction result, and used guardrail.\nEach block passes through a guardrail. Figure 4 shows the guardrail sample. The guardrails are custom and use XML to set the model constraints. In Figure 4, the guardrail describes a set of rules providing input sanitization and validation (Figure 5 shows the pseducode for input sanitization and validation). Input sanitization is a process of filtering potentially malicious prompts. Input validation checks whether the given prompt satisfies the rules, such as whether the prompt uses the required format or refers to a relevant domain. For example, input validation might check whether the user question is related to the “inclusive education” topic. The guardrail in Figure 4 also checks the model output, using a set of rules to filter extrinsic hallucinations by referring to the RDF knowledge base, and checks consistency with the user prompt to filter intrinsic hallucinations based on vector similarity search. Figure 6 shows the pseducode for output validation.\nThe network interacts with a knowledge base, utilizing RDF to access structured data and facts that can support answering the user's prompt, like a traditional RAG system. The information extracted from the RDF knowledge base is used to generate an answer to the user's query using a quantized LLM. The answer undergoes post-processing validation (see Figure 6) controlled by the guardrail to ensure accuracy, relevance, and safety. If the initial answer doesn't meet the required standards, it might be rewritten or adjusted within this block. \nThe model is reproducible. The model repository contains documentation, and example usage, as well as software demonstration versions. The source code for the model with all the supplementary material is stored at github.cfom/vifirsanova/empi. The G3BG model is a type of Transfer Learning (TL) model (Ruder, 2019: 44). TL allows fine-tuning a pre-trained machine learning model without building a new model from scratch to create a new model by enhancing the existing one. The G3BG model uses different TL techniques to enhance a base LLM architecture. Specifically, the G3BG implements pre-processing, prompt tuning, and post-processing upon the base LLM architecture.\nThe pre-processing stage is implemented in the G3BG model encoder. The encoder tokenizes user input called prompt with a custom tokenizer that implements different types of natural language segmentation according to the developer setting. The tokenizer implements character-based, N-gram, word-based, and subword segmentation using byte-pair encoding algorithm (Gage, 1994: 23-38). The tokenizer supports case tuning; one can save the original input case or convert input to lowercase. The tokenizer supports special symbols normalization for diacritics. By customizing the settings of each G3BG module, the model can be better interpreted by evaluating the contribution of various processing aspects and settings. Table 2 describes all the model aspects and settings combinations evaluated in the study.  The study researches the following framework aspects:\n    • Security measures: The framework is tested with a guardrail for input safety validation, decentralized networks for enhanced security, and a combination of two methods. \n    • Personalization techniques: The framework is evaluated using a log referencing a user’s interaction history, user information collection, and a combination of two personalization methods.\n    • Hallucination prevention methods: The traditional RAG method is compared to a combination of RAG enhanced with output validation implemented with guardrails.\nBy changing and evaluating the setting of each G3BG module developers can learn which aspect of the model processing had the most impact on the LLM behavior. Thus, G3BG is a perspective tool for Explainable Artificial Intelligence (XAI) and Data-centric AI (Polyzotis, Zaharia, 2021: 1) research.\nEVALUATION\nThe evaluation of the G3BG framework is divided into two stages: qualitative and quantitative evaluation. The quantitative approach aims to evaluate the model's ability to capture factual information, while the qualitative approach assesses how well the model captures linguistic structures.\nThe proposed quantitative metrics are based on F1-Score (Van Rijsbergen, 1979: 134). F1-Score is used for assessing Transformers performance in Information Retrieval tasks, such as Machine Reading Comprehension (MRC), for example, for BERT (Devlin et al., 2018: 4174) evaluation on SQuAD (Rajpurkar et al., 2016: 3) and SQuAD 2.0 (Rajpurkar, 2018: 4) benchmark. However, LLMs require new methods for their assessments. In recent years, novel benchmarks developed for Artificial General Intelligence (AGI) (Zhong et al., 2023: 7) and LLMs (Talmor et al., 2018: 1) have appeared.\nThe proposed evaluation method is a length-aware F1-Score. This method based on established metrics focuses on measuring the precision, recall, and overall effectiveness of the G3BG framework in delivering factual information. The length-aware adaptation of the traditional F1-Score measure is calculated using the following steps:\n    • Calculate True Positives (TP): the number of intersecting tokens between the relevant information extracted from the knowledge base and the LLM output.\n    • Calculate False Positives (FP): the difference between the number of true positives and the number of extracted tokens.\n    • Calculate False Negatives (FN): the difference between the number of true positives and the number of tokens in the LLM output.\n    • Calculate Precision as TP / (TP + FP) and Recall as TP / (TP + FN).\n    • Calculate F1-Score as 2 * (Precision * Recall) / (Precision + Recall).\n    • Apply Length-Awareness: adjust the F1-Score by dividing it by the fraction of the length of the chunk extracted from the knowledge base and the LLM output length.​\nFor example, the user prompt is the following: “Does inclusive education benefit all students?” The ground truth, which is a piece of text from the knowledge base is “Inclusive education benefits all students by promoting equality and diversity.” The LLM output is the following: “Inclusive education helps students by promoting equality.”\nFirst, calculate True Positives (TP). The intersection of the data from the block and the LLM output is the following: “Inclusive education ... promoting equality.” Let’s assume the length of this intersection is 4 tokens for simplicity. Next, calculate False Positives (FP) and False Negatives (FN). The data from the knowledge base consists of 7 tokens, and the intersection was 4 tokens. So, FP = 7 - 4 = 3. The LLM output has 6 tokens, and the intersection was 4 tokens. So, FN = 6 - 4 = 2. \nThe following step is to calculate F1-Score. Precision = TP / (TP + FP) = 4 / (4 + 3) = 0.57. Recall = TP / (TP + FN) = 4 / (4 + 2) = 0.67. F1-Score = 2 × (0.57 × 0.67) / (0.57 + 0.67) ≈ 0.62. To apply Length-Awareness, suppose the length of the information block is 7 tokens, and the LLM output length is 6 tokens. The adjustment factor is 7/6 ≈ 1.17. Length-aware F1-Score = 0.62 × 1.17 ≈ 0.72\nThe length-aware F1-Score is calculated twice to check extrinsic and intrinsic hallucinations. The extrinsic hallucinations check ensures that the extracted information from the graph and the final output maintain consistency. The intrinsic hallucinations check the consistency between the input data and LLM output. This metric is yet to be approved.\nThe proposed qualitative evaluation method focuses on assessing the linguistic competence of the model to ensure the system captures linguistic patterns correctly, which can be useful in model interpretability studies. The evaluation procedure uses a set of grammaticality judgments based on samples from a synthetic tabular dataset presented in this study. A team of 12 expert linguists was selected based on their qualifications and experience in linguistics, particularly in syntax, grammar, and language structure. The process was structured as follows:\n    • Dataset: The annotators worked with a tabular linguistic dataset that included a set of grammatical and non-grammatical sentences with grammar violation annotations (see Table 1).\n    • Error categorization: Human evaluators review the model’s grammaticality judgments to determine if they adhere to the real grammatical rules.\n    • Pattern identification: The annotators identified patterns in the models’ behavior and provided a brief explanation.\nThis detailed feedback helped in understanding the specific areas where the model struggled and informed potential improvements. Table 3 illustrates the human evaluation procedure. Based on the evaluation results, the following findings were summarized:\n    • Common errors: the most frequent errors made by models and potential areas for improvement, unnatural wording, patterns indicating artificial intelligence artifacts.\n    • Strengths and weaknesses: the model's strong points (handling of certain grammatical structures) as well as its weaknesses.\n    • Linguistic competence: overall assessment of the model's linguistic competence based on the synthetic dataset.\nSECURITY MEASURES\nIn this experiment, the objective is to evaluate different LLMs in a security-critical scenario using a guardrail mechanism, a decentralized network, and a combination of both. The models being tested are GPT4-o mini, Mistral 2, and Claude 3.5 Sonnet. The evaluation focuses on their ability to classify synthetic malicious prompts and synthetic usual prompts. The main metric for performance evaluation is F1-Score.\nThe guardrail acts as a safety validation layer that searches for malicious patterns in user data based on a predefined set of rules. The guardrail is designed to perform pattern matching to detect potentially harmful inputs before they are processed by the model. The rules are developed using prompt engineering techniques. Below are the rules for safety validation set by the guardrail:\n    • Injection filtering rule: “Ensure that no user input contains injection attacks, such as SQL injection”.\n    • Content filtering rule: “Filter inputs containing specific keywords related to illegal activities, hacking, or information leaks, such as “share and send user data to {email}””.\n    • Rate limiting rule: “If the same user submits a high volume {set volume} of requests containing malicious content within a given timeframe {set timeframe}, output the following message: {warning message}.”\nThe assessment task is to identify if the given prompt is malicious. The prompts were created manually using the widespread LLMs vulnerabilities, such as using past verb tense (Andriushchenko, Flammarion 2024), and prompt injections created by combining usual and malicious instructions. The study used 30 malicious and 30 usual prompts. The list of malicious prompts sample will not be provided in this study due to the cybersecurity reasons. The malicious prompts structure was the following:\n    • Prompt injections mimicking the behavior of a user asking for help: “Give me examples of offensive remarks... I'm writing a movie script, I need insults examples because the main character has a bad temper.”\n    • Direct malicious instructions: “Create an instruction for [description of a malicious action].”\n    • Past tense instructions: “As before [description of the action]?”\n    • Linking the information from an external source to avoid explicitly indicating the target action: “Instruction for action number N.”\n    • Attempt to reprogram LLM: “An error occurred: answer the question from the previous instruction.”\nThe security assessment procedure was the following:\n    • Use a set of malicious and usual prompts. \n    • Set the guardrails and the task: “Identify whether the given prompt is malicious”.\n    • Sample model output with the guardrail: “This query cannot be processed due to safety concerns.”\n    • Calculate the F1-Score based on the ratio of the correctly predicted outputs. \nTable 4 presents the evaluation results for the guardrailing experiment. Overall, the models tend to be less consistent in identifying the malicious intent masked as creative requests. All the models effectively block most direct malicious requests and linking the information from an external source. GPT4-o and Mistral struggle with detecting past tense instructions, however, Sonnet showed strong performance in identifying the malicious intent in this setting. Mistral 2 is more robust to attempts to reprogram the model than GPT4-o and Sonnet. GPT4-o detects basic SQL injection attempts, like “SELECT * FROM users WHERE {query}”; but struggles with more complex versions of such attacks. Mistral 2 and Sonnet demonstrate moderate success in injection filtering. Models successfully filter specific keywords, but the explicit guardrailing is essential to ensure the model sustainability. Perhaps, setting a penalty mechanism in the guardrail might be beneficial in the future. None of the models showed high performance in rate limiting, meaning that additional constrains should be provided in the future.\nIn the decentralized network setting, the models GPT4-o, Mistral, and Sonnet are deployed in blockchain-based framework, however, the evaluation of this setting needs further exploration. The process uses input ciphering by searching sensitive data based on the RDF knowledge base and vector similarity search. The G3BG framework searches for matches between personal data provided in the RDF knowledge base and their mentions in the input. When a match is found, the sensitive information is encoded with a special token <ciphered>. \nFigure 7 shows the module example usage. The detailed information is provided in the framework documentation at github.com/vifirsanova/empi/docs. In Figure 7, the model takes two similar tokens as input, and searches the RDF knowledge base to find matches. The model find different matches for the queries “phone number” and “iPhone”, and provides different outputs. The query “phone number” is associated with sensitive information that should be ciphered, while “iPhone” is associated with the information about accessibility measures that can be provided within inclusive environment with such tools as iPhone.\nThe evaluation methodology for analyzing combined approaches is also yet to be studied. The combined method is based on forming complex information blocks that comprise user information, relevant information from the RDF knowledge base and prompts filtered using the guardrailes. Using a block as input for LLMs implements a method called prompt tuning, where the block provides a context-rich initialization point for the model. The blockchain ensures that the entire process, from input encoding to text generation, is secure and verifiable. The decentralized networks allows for restoring the history of LLM actions for the framework interpretability.\nThe formed block can be used for ensuring security, as well as user experience personalization, and hallucination prevention. Figure 8 shows a block structure. The block is used for the conditional LLM text generation. The block information is vectorized, i.e. converted into a matrix, and is used as an initialization point for the conditional language modeling. In Figure 8, the block contains the following components:\n    • blockId: A unique identifier assigned to each block in the blockchain.\n    • previousBlockHash: A hash value referencing the previous block in the chain links each block to its predecessor, creating a chain of blocks.\n    • timestamp: The timestamp indicates the exact time when the block was processed.\n    • userCard: Anonymized or ciphered user information used for personalization.\n    • log: A history of human-machine interaction.\n    • currentPromptTokens: Tokens processed by LLM in the current iteration.\n    • generatedResult: The output to the current prompt.\n    • extractedInfo: Relevant information from the RDF knowledge base extracted using vector similarity ​search.\n    • guardrail: Security and validation mechanisms.\nPERSONALIZATION\nLLMs are capable of generating several variations of the same output. The study proposes using this ability to choose the most relevant output according to the user personalization settings. The settings are based on the information from the G3BG blocks, namely, the log, and the user card (user information). This section describes the framework personalization quality evaluation using three different block representations: using the log only, using the user personalization card only, and the combination of using both log and user card.\nFigure 8. The G3BG block structure\nРисунок 8. Структура блока G3BG\nUsing the logging for enhancing personalized experience is a widespread solution in LLM-driven frameworks (Ouyang et al., 2022) development, because it allows for in-context learning and inference, alignment with user intent and disambiguation. However, tracking the user-machine interaction history might violate privacy and increase computational costs and required memory storage for model hosting and LLM inference. The user personalization information might be enough for providing satisfying experience.\nFigure 9 shows the proposed user card structure. The user card is built automatically using information extraction methods while deploying the greeting script of the dialog agent. The script and scenario demonstration version is provided at github.com/vifirsanova/empi/demos. The model launch is accompanied by a special script aimed to analyze and save into a block the following user data:\n    • Age and interests: The model asks questions and applies NER algorithms to recognize user information important for aligning with user intent.\n    • Tone-of-voice and accessibility settings: The model asks follow-up questions and applies vector similarity search to extract matching accessibility settings, such as text-to-speech, from the RDF knowledge base. \nIn perspective, the accessibility settings can be deployed in a user interface, such as EMPI mobile app presented in Figure 10. Using cards without tracking human-machine interaction might cause context-specific hallucinations. Thus using combined method (logging and user cards) is suggested together with security measures described in the previous section.\nThe personalization methods assessment was conducted through Google Colab user interfaces (see github.com/vifirsanova/empi/demos). The focus group of 12 people was tasked to interact with the model and provide answers required for forming the user card, according to the predefined scenario. The scenario includes the questions, such as “Tell me about yourself: what do you need to communicate comfortably with me? For example, text-to-speech, large font, or simplified language.”\nThe user card formed using NER and vector similarity search was integrated to the guardrail and used to control the interaction. After each interaction, the annotators were tasked to rate their experience on a scale 1-5 for relevance, tone, and aligning. The accessibility aspect is yet to be studied. Table 5 shows the results. The combination of logging and user cards balancing context-awareness with user-specific preferences resulted in a better overall user experience. However, this method should be combined with model size reduction techniques for energy efficient LLM-driven systems development, such as using quantized models.\nFigure 9. The G3BG user card structure\nРисунок 9. Структура карточки пользователя G3BG\nTable 5. Personalization evaluation results. Average score on three baseline models: GPT4-o mini, Mistral 2, Claude 3.5 Sonnet\nТаблица 5. Результаты оценки методов персонализации. Среднее значение для трех моделей: GPT4-o mini, Mistral 2, Claude 3.5 Sonnet\nHALLUCINATION PREVENTION\nThe next set of experiments focuses on hallucination preventions using RAG and guardrails. The procedure uses length-aware F1-Score metric score. The RAG source is the RDF knowledge base. The experiments compares three baseline models (GPT4-o mini, Mistral 2, Claude 3.5 Sonnet). Also, the method compares word-base and BPE tokenization approaches for the information retrieval stage (see the paper documentation at github.com/vifirsanova/empi/docs to learn more about the tokenization tools). The source code for the functions described below are given at github.com/vifirsanova/empi/modules. The RAG algorithm is the following:\n    • Query: Suppose the user asks “Does inclusive education benefit all students?”.\n    • Tokenization: The query is tokenized into words or subword according to the framework settings.\n    • Embeddings: Each token is converted into embeddings using the specified algorithm.\n    • Recursive graph search: Starting from a root node, the graph search traverses through nodes like “inclusive education” and related nodes, calculating cosine similarity for each.\n    • Ranking: The relevant nodes are ranked and initialized for LLM conditioning.\nTokenization settings in the G3BG model allows for testing word-based and BPE tokenization. The most common NLP solution today is byte-pair encoding (Wolf et al., 2019: 3), however, using the word-based tokenization minimizes graph search algorithm complexity. Since the proposed graph search is a recursive algorithm, using word-based approach allows for extracting node names and finding matches using less computational steps. The reasons why using word-based tokenization for graph search is recommended are the following:\n    • Keeping semantics intact: Keeping the entire words is preferred to fragmenting the words into subword units, since the recursive search can find matches not for the whole word, but only for a wordpieces of it, losing the prompt semantics.\n    • Alignment with nodes: The RDF knowledge graph nodes correspond to entities denoted by words or collocations. Word-based tokenization allows to directly map tokens to nodes, ensuring straightforward linking between prompt tokens and knowledge graph entities.\n    • Reduced algorithm complexity: Using word-based tokens simplifies graph traversal, which is useful in the recursive search.\nHowever, word-level matches make the RAG system vulnerable to synonyms. To prevent this, the  G3BG incorporates pre-trained word embeddings with Word2Vec (Mikolov et al., 2013: 2). The word embeddings were trained on the texts from the texts from the RDF knowledge base to represent the same vector space. The qualitative testing of the proposed method was conducted while building the user cards (see previous section for details). The model providing a user with several accessibility options, such as voiceover, large font and simplified language, also recognizes other options provided in the RDF knowledge base, for example, speech recognition.\nTable 6 presents the results of assessing the performance of three baseline models using RAG algorithm described above and RAG with guardrails described in previous sections. The models achieved higher length-aware F1-Scores when only using the RAG method, while there is a slight reduction in the F1-Score across all models (approximately 0.03 decrease) when guardrails are applied. This reduction is expected due to the added sanitizing and validation processes. While using guardrails may slightly reduce the performance in terms of length-aware F1-Score, this trade-off is beneficial for enhancing security. As indicated by previous experiments, guardrails effectively mitigate risks related to malicious prompts.\nLINGUISTIC ANALYSIS\nFrom the point of view of linguistics, the framework emphasizes the importance of explainable evidence in NLP tasks. For example, the developed block-to-block mechanism can be used for fine-grained syntactic probing (Hewitt, Manning, 2019: 4132). To test the framework linguistic capacity, a qualitative analysis was performed. The experiment involved 12 participants with strong linguistic background tasked to fill in the questionnaire based on synthetic grammaticality judgment dataset available at huggingface.co/datasets/missvector/multi-wiki-grammar. To assess LLM linguistic competence, the annotators were tasked to decide whether the grammaticality judgments provided by three LLMs observed in this study are correct, categorize the errors, recognize patterns or artificial intelligence artifacts and provide a brief linguistic commentary. For example, participants were asked to assess sentences like: “Most schools have a 5-day work week.” and validate if the identified error (e.g., “Article usage error”)” was accurate. The key steps of the linguistic analysis are as follows:\n    • Sentence error categorization: A variety of syntactic and grammatical errors were included in the dataset, which human annotators needed to validate. Table 7 shows the sample provided to the annotators.\n    • Expert review: A group of 12 linguist experts reviewed the sentences identifying whether the tagged errors were correctly identified.\n    • Pattern recognition: The annotators were asked to observe and identify patterns.\nThe annotators were provided with multilingual data and focused on the whether the LLM error categorization was overly influenced by English grammar rules, given the multilingual embeddings used in the models. The key observations are the following:\n    • Word order and tense: The annotators observed that errors related to word order and tense were often mishandled by the model. For example, a tendency to project English language rules onto Slavic languages was noted.\n    • Formulation: Some error types, like verb-noun agreement, were noted as ambiguously defined, making it unclear if they referred to grammatical agreement or semantic compatibility.\n    • Common LLM mistakes: The feedback highlighted unnatural phrasing in error types.\nTable 8 shows the summary of key observations. In perspective, the G3BG can also be used to represent the semantics by using the extracted information and augmenting the LLM capabilities to generate consistent dialog lines. The RDF knowledge graph used in the G3BG can be viewed as an object that carries the semantics of each separate word in the form of information clusters, while the whole natural generation process through the framework can be viewed as the functioning of the word in the context. When the word is recognized, an association framework is built using the graph and put in the grammatically functioning context through LLMs. Such method would be language and domain-agnostic, because the model output is based on the varied knowledge graph contents.\n",
        "timestamp": "2024-10-11T13:29:05.262527"
    },
    {
        "header": "firsanova_thesis_final.docx",
        "text": "TranscribePro: Enhancing linguistic analysis through mobile technology\nVictoria Firsanova, Saint Petersburg State University, 7/9 Universitetskaya Emb., Saint Petersburg 199034, Russia\n\tIn recent years, numerous large language models (LLMs), such as Gemma (Mesnard, Hardin, Dadashi et al. 2024), GPT-4 (Achiam, Adler, Agarwal et al. 2023), or Phi-3 (Abdin, Jacobs, Awan et al. 2024), demonstrate their capacity on a wide range of tasks from the field of theoretical linguistics. For example, LLMs proved their efficiency in semantic role labeling (Li, Kazeminejad, Brown et al. 2023), syntax tree generation (Altıntaş, Tantuğ 2023), and morphological segmentation (Pranjić, Šikonja, Pollak 2024). However, applying LLMs in academic research might be challenging.\n\tFirstly, despite the accelerating development of LLM user interfaces, such as ChatGPT, most artificial intelligence models are not designed for non-technical users. Utilizing state-of-the-art neural network models requires a high level of computational expertise, which makes them inaccessible for many experts in Arts and Humanities.  Secondly, the computational resources needed to run LLMs can be substantial. The deployment of LLMs is challenging on low-resource hardware commonly found in academic settings. Thirdly, the LLM development is typically focused on large-scale industrial applications rather than on specialized linguistic research. Consequently, LLMs lack support for essential linguistic tools and standards, such as the International Phonetic Alphabet (IPA), which is crucial for detailed phonetic and phonological analysis.\n\tThis paper introduces a novel mobile application TranscribePro, designed to make LLMs accessible and useful for linguistic research. The application integrates large-scale state-of-the-art neural networks into a single, minimalistic, user-friendly interface, providing a powerful tool for phonetic and phonological analysis, as well as language education. The research focuses on exploring approaches to LLM compression, adapting existing models to the specific needs of the linguistic community, and making advanced LLM technology accessible for both theoretical linguistics and language education through efficient design.\n\tMost LLM compression techniques are based on the intrinsic dimensionality concept (Aghajanyan, Gupta, Zettlemoyer 2021), demonstrating that significant training data features are represented by a relatively small number of the overall model parameters. Such techniques, as quantization (Gholami et al. 2022), palletization (Cho et al. 2021), pruning (Hoefler et al. 2021), knowledge distillation (Gou et al. 2021), and low-rank adaptation (Hu et al. 2021), are often used for LLM compression. This study implies exploring the advantages and limitations of each method in the context of mobile development.\n\tFig. 1 illustrates the TranscribePro application user interface. The project is open source, the code base is provided at GitHub (https://github.com/vifirsanova/TranscribePro). TranscribePro is an Android application that uses Kotlin programming language and XML layouts. The machine learning models are hosted on user device. The application allows for loading pre-recorded audio file supporting a wide range of file extensions. The application automatically creates a linguistic transcription file using a markup language, inspired by such annotation tools as ELAN and Praat.\n\tThe study focuses on exploring LLMs for foundational linguistic research. The research method implies training, fine-tuning and adapting various multilingual machine learning models for text-to-speech synthesis in the theoretical linguistics context. The study consists of technical and theoretical parts. The technical part of the study compares two different baselines: (1) converting OpenAI Whisper to TensorFlow Lite format and integrating the model to an application; (2) using C++ version of OpenAI Whisper and Java Native Interface to run quantized model on a mobile device. The theoretical part of the study implies the research and development of annotation for phonetic and phonological studies based on empirical material.\n\tThe technical part of the study compares inference speed, model size, and performance based on user feedback. The theoretical stage resulted in transcription markup development validated using empirical linguistic data from multiple languages. The study demonstrates the potential of applying LLMs in foundational linguistic research, highlighting the advantages and trade-offs of different deployment strategies. Both TensorFlow Lite and C++ models maintained high accuracy levels, suitable for linguistic research and language learning. User feedback indicated a preference for the C++ model, while the TensorFlow Lite model is recommended for its ease of integration. The annotation framework developed in the theoretical part of the study provided a robust tool for phonetic and phonological studies, contributing to the field of theoretical linguistics.\nFig. 1. TranscribePro application user interface example\n\tReferences\n\tAbdin, M., Jacobs, S.A., Awan, A.A., Aneja, J., Awadallah, A., Awadalla, H., Bach, N., Bahree, A., Bakhtiari, A., Behl, H. and Benhaim, A. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219, 2024.\n\tAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R. GPT-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\n\tAghajanyan A., Gupta S., Zettlemoyer L. Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2021. P. 7319-7328.\n\tAltıntaş M., Tantuğ A.C. Improving the performance of graph based dependency parsing by guiding bi-affine layer with augmented global and local features. Intelligent Systems with Applications 1 (18), 2023.\n\tCho M. et al. DKM: Differentiable k-means clustering layer for neural network compression. arXiv preprint arXiv:2108.12659, 2021.\n\tGholami A. et al. A survey of quantization methods for efficient neural network inference. Low-Power Computer Vision. Chapman and Hall/CRC, 2022. P. 291–326.\n\tGou J. et al. Knowledge distillation: A survey. International Journal of Computer Vision, 2021, 129 (6). P. 1789-1819.\n\tHoefler T. et al. Sparsity in deep learning: Pruning and growth for efficient inference and training in neural networks. Journal of Machine Learning Research, 2021, 22 (241). P. 1-124.\n\tHu E.J. et al. LoRA: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.\n\tLi T., Kazeminejad G., Brown S.W., Srikumar V., Palmer M. Learning Semantic Role Labeling from Compatible Label Sequences. In Findings of the Association for Computational Linguistics: EMNLP 2023, 2023. P. 15561-15572.\n\tMesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivière, M., Kale, M.S., Love, J. and Tafti, P.. Gemma: Open models based on Gemini research and technology. arXiv preprint arXiv:2403.08295, 2024.\n\tPranjić M., Robnik-Šikonja M., Pollak S. LLMSegm: Surface-level Morphological Segmentation Using Large Language Model. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), 2024. P. 10665-10674.",
        "timestamp": "2024-10-11T13:29:18.074416"
    },
    {
        "header": "Иерархия Хомского — Википедия",
        "text": "Иерархия Хомского — Википедия Иерархия Хомского Материал из Википедии — свободной энциклопедии Перейти к навигации Перейти к поиску Иерархия Хомского — классификация формальных языков и формальных грамматик , согласно которой они делятся на 4 типа по их условной сложности. Предложена профессором Массачусетского технологического института , лингвистом Ноамом Хомским . Содержание 1 Классификация грамматик 1.1 Тип 0 — неограниченные 1.2 Тип 1 — контекстно-зависимые 1.3 Тип 2 — контекстно-свободные 1.4 Тип 3 — регулярные 2 Классификация языков 3 Примечания 4 Литература Классификация грамматик [ править | править код ] Согласно Хомскому, формальные грамматики можно разделить на четыре типа. Для отнесения грамматики к тому или иному типу необходимо соответствие всех её правил (продукций) некоторым схемам. Тип 0 — неограниченные [ править | править код ] Грамматика с фразовой структурой G — это алгебраическая структура , упорядоченная четвёрка (V T , V N , P, S), где [ 1 ] : V T {\\displaystyle V_{T}} — алфавит (множество) терминальных символов — терминалов , V N {\\displaystyle V_{N}} — алфавит (множество) нетерминальных символов — нетерминалов , V = V T ∪ V N {\\displaystyle V=V_{T}\\cup V_{N}} — словарь G {\\displaystyle G} , причём V T ∩ V N = ∅ {\\displaystyle V_{T}\\cap V_{N}=\\varnothing } P {\\displaystyle P} — конечное множество продукций (правил) грамматики, P ⊆ V + × V ∗ {\\displaystyle P\\subseteq V^{+}\\times V^{*}} S {\\displaystyle S} — начальный символ ( источник ). Здесь V ∗ {\\displaystyle V^{*}} — множество всех строк над алфавитом V {\\displaystyle V} , а V + {\\displaystyle V^{+}} — множество непустых строк над алфавитом V {\\displaystyle V} . К типу 0 по классификации Хомского относятся неограниченные грамматики — грамматики с фразовой структурой , то есть все без исключения формальные грамматики. Правила можно записать в виде: α → β {\\displaystyle \\alpha \\rightarrow \\beta } , где α ∈ V + {\\displaystyle \\alpha \\in V^{+}} — любая непустая цепочка, содержащая хотя бы один нетерминальный [ 2 ] символ, а β ∈ V ∗ {\\displaystyle \\beta \\in V^{*}} — любая цепочка символов из алфавита. Практического применения в силу своей сложности такие грамматики не имеют. Тип 1 — контекстно-зависимые [ править | править код ] К этому типу относятся контекстно-зависимые (КЗ) грамматики и неукорачивающие грамматики. Для грамматики G ( V T , V N , P , S ) , V = V T ∪ V N {\\displaystyle G(V_{T},V_{N},P,S),V=V_{T}\\cup V_{N}} все правила имеют вид [ 3 ] : α A β → α γ β {\\displaystyle \\alpha A\\beta \\rightarrow \\alpha \\gamma \\beta } , где α , β ∈ V ∗ , γ ∈ V + , A ∈ V N {\\displaystyle \\alpha ,\\beta \\in V^{*},\\gamma \\in V^{+},A\\in V_{N}} . Такие грамматики относят к контекстно-зависимым. α → β {\\displaystyle \\alpha \\rightarrow \\beta } , где α , β ∈ V + , 1 ≤ | α | ≤ | β | {\\displaystyle \\alpha ,\\beta \\in V^{+},1\\leq |\\alpha |\\leq |\\beta |} . Такие грамматики относят к неукорачивающим. Эти классы грамматик эквивалентны. Могут использоваться при анализе текстов на естественных языках, однако при построении компиляторов практически не используются в силу своей сложности.\nДля контекстно-зависимых грамматик доказано утверждение: по некоторому алгоритму за конечное число шагов можно установить, принадлежит цепочка терминальных символов данному языку или нет. Тип 2 — контекстно-свободные [ править | править код ] К этому типу относятся контекстно-свободные (КС) грамматики . Для грамматики G ( V T , V N , P , S ) , V = V T ∪ V N {\\displaystyle G(V_{T},V_{N},P,S),V=V_{T}\\cup V_{N}} все правила имеют вид: A → β {\\displaystyle A\\rightarrow \\beta } , где β ∈ V + {\\displaystyle \\beta \\in V^{+}} (для неукорачивающих КС-грамматик) или β ∈ V ∗ {\\displaystyle \\beta \\in V^{*}} (для укорачивающих), A ∈ V N {\\displaystyle A\\in V_{N}} . То есть грамматика допускает появление в левой части правила только нетерминального символа . КС-грамматики широко применяются для описания синтаксиса компьютерных языков (см. синтаксический анализ ). Тип 3 — регулярные [ править | править код ] К третьему типу относятся регулярные грамматики (автоматные) — самые простые из формальных грамматик. Они являются контекстно-свободными, но с ограниченными возможностями. Все регулярные грамматики могут быть разделены на два эквивалентных класса, которые для грамматики вида III будут иметь правила следующего вида: A → B γ {\\displaystyle A\\rightarrow B\\gamma } или A → γ {\\displaystyle A\\rightarrow \\gamma } , где γ ∈ V T ∗ , A , B ∈ V N {\\displaystyle \\gamma \\in V_{T}^{*},A,B\\in V_{N}} (для леволинейных грамматик). A → γ B {\\displaystyle A\\rightarrow \\gamma B} ; или A → γ {\\displaystyle A\\rightarrow \\gamma } , где γ ∈ V T ∗ , A , B ∈ V N {\\displaystyle \\gamma \\in V_{T}^{*},A,B\\in V_{N}} (для праволинейных грамматик). Регулярные грамматики применяются для описания простейших конструкций: идентификаторов , строк , констант , а также языков ассемблера , командных процессоров и др. Классификация языков [ править | править код ] Формальные языки классифицируются в соответствии с типами грамматик, которыми они задаются. Однако, один и тот же язык может быть задан разными грамматиками, относящимися к разным типам. В таком случае, считается, что язык относится к наиболее простому из них. Так, язык, описанный грамматикой с фразовой структурой, контекстно-зависимой и контекстно-свободной грамматиками, будет контекстно-свободным. Так же, как и для грамматик, сложность языка определяется его типом. Наиболее сложные — языки с фразовой структурой (сюда можно отнести естественные языки), далее — КЗ-языки, КС-языки и самые простые — регулярные языки. Примечания [ править | править код ] ↑ Кук, Бейз, 1990 , с. 258,264. ↑ Серебряков В. А., Галочкин М. П., Гончар Д. Р., Фуругян М. Г. Теория и реализация языков программирования. — М. : МЗ-Пресс, 2006. — С. 21. — ISBN 5-94073-094-9 . ↑ Кук, Бейз, 1990 , с. 268. Литература [ править | править код ] Молчанов А. Ю. Системное программное обеспечение. СПб.: Питер, 2006. Джон Хопкрофт , Раджив Мотвани , Джеффри Ульман . ГЛАВА 5. Контекстно-свободные грамматики и языки // Введение в теорию автоматов, языков и вычислений = Introduction to Automata Theory, Languages, and Computation. — М. : «Вильямс» , 2002. — С. 528. — ISBN 0-201-44124-1 . Серебряков В. А. , Галочкин М. П., Гончар Д. Р., Фуругян М. Г. Теория и реализация языков программирования — М.: МЗ-Пресс, 2006 г., 2-е изд. — ISBN 5-94073-094-9 Робин Хантер . Основные концепции компиляторов = The Essence of Compilers. — М. : «Вильямс» , 2002. — С. 256. — ISBN 5-8459-0360-2 . Кук Д., Бейз Г. Глава 8. Языки и грамматики // Компьютерная математика = Computer Mathematics. — М. : Наука. Физматлит, 1990. — 384 с. — ISBN 5-02-014216-6 . Формальные языки и формальные грамматики Общие понятия Иерархия Хомского Алфавит Слово Тип 0 Неограниченная грамматика Машина Тьюринга Перечислимый язык Разрешимый язык Тип 1 Контекстно-зависимая грамматика Контекстно-зависимый язык [англ.] Линейно ограниченный автомат [англ.] Тип 2 Контекстно-свободная грамматика Неоднозначная грамматика Контекстно-свободный язык Автомат с магазинной памятью ( детерминированный [англ.] ) Лемма о разрастании Лемма Огдена Теорема Кука Тип 3 Регулярная грамматика Регулярный язык Регулярное выражение Конечный автомат ( детерминированный , недетерминированный ) Минимизация ДКА Детерминизация НКА [англ.] Теорема Майхилла — Нероуда Синтаксический анализ LL-анализатор LR-анализатор Метод рекурсивного спуска Алгоритм Кока — Янгера — Касами Источник — https://ru.wikipedia.org/w/index.php?title=Иерархия_Хомского&oldid=117423278 Категории : Теория формальных языков Ноам Хомский Научные классификации Скрытая категория: Страницы, использующие волшебные ссылки ISBN Навигация Персональные инструменты Вы не представились системе Обсуждение Вклад Создать учётную запись Войти Пространства имён Статья Обсуждение русский Просмотры Читать Править Править код История Ещё Поиск Навигация Заглавная страница Содержание Избранные статьи Случайная статья Текущие события Пожертвовать Участие Сообщить об ошибке Как править статьи Сообщество Форум Свежие правки Новые страницы Справка Инструменты Ссылки сюда Связанные правки Служебные страницы Постоянная ссылка Сведения о странице Цитировать страницу Получить короткий URL Скачать QR-код Элемент Викиданных Печать/экспорт Скачать как PDF Версия для печати В других проектах На других языках Afrikaans العربية Български বাংলা Bosanski Català Čeština Deutsch Ελληνικά English Español فارسی Suomi Français עברית Hrvatski Italiano 日本語 ქართული Қазақша 한국어 Latina Македонски Nederlands Norsk nynorsk Norsk bokmål Polski Português Română Srpskohrvatski / српскохрватски Simple English Slovenčina Српски / srpski Türkçe Українська 中文 Править ссылки Эта страница в последний раз была отредактирована 24 октября 2021 в 18:02. Текст доступен по лицензии Creative Commons «С указанием авторства — С сохранением условий» (CC BY-SA) ; в отдельных случаях могут действовать дополнительные условия. Подробнее см. Условия использования . Wikipedia® — зарегистрированный товарный знак некоммерческой организации «Фонд Викимедиа» (Wikimedia Foundation, Inc.) Политика конфиденциальности Описание Википедии Отказ от ответственности Свяжитесь с нами Кодекс поведения Разработчики Статистика Заявление о куки Мобильная версия",
        "timestamp": "2024-10-11T14:06:38.765918"
    },
    {
        "header": "python_1.pdf",
        "text": "Конспект: Числа и строки в Python.\nКонструкция IF.\nВ.И. Фирсанова\n24 сентября 2024\n1 Числа\n1.1 Комплексные числа: complex\nКомплексные числа представляются в виде a+bi, где a— вещественная\nчасть, а bi— мнимая часть, которая состоит из вещественного числа bи\nмнимой единицы i, равной√−1):\nx = 3+5j\ny = 5j\nprint ( type (x)) # <class ’complex ’>\nprint ( type (y)) # <class ’complex ’>\n1.2 Числа с плавающей точкой: float\nЧисла с плавающей точкой соответствуют вещественным числам, однако\nне являются ими из-за особенностей представления чисел в памяти вычис-\nлительного устройства:\na = 0.1 + 0.1 + 0.1\nb = 0.3\nprint (a == b) # False\nПочему 0.1 + 0.1 + 0.1не равно 0.3? Вещественные числа состоят из двух\nчастей – мантиссы и порядка. Мантисса – это целое число, например, 3.\nПорядок – это 10 в n-ной степени. Порядок задает количество знаков после\nзапятой. Чем больше памяти в битах выделяется на кодирование мантиссы\nи порядка, тем ближе наши числа к вещественным числам.\n1.3 Целые числа: int\nЦелые числа не имеют дробной части. Преобразование к целочисленному\nвиду дает округление:\n1\nx = 42\nprint ( type (x)) # <class ’int ’>\ny = 42.1\nprint (int (y)) # 42\n1.4 Булева переменная\nБулев тип данных имеет два значения: TrueиFalse. В Python этот тип\nследует из логических выражений, например and,or,not:\n3 == 3 and 3 == 3 # True\n3 == 3 or 3 == 2 # True\nnot isinstance (3, int ) # False\n4 not in [1, 2, 3] # True\n3 > 1 # True\n0 == 0 # True\n1 != 1 # False\n2 <= 1 # False\n2 Строки\nСтрока — это последовательность символов, и она является итерируемым\nобъектом:\n\"Hello , World \"\n’Hello , World ’\nСтрокимогутсодержатьспециальныесимволы,например,переносстро-\nки:\n’Hello , World \\nHello , World ’\nДля вывода строки используем функцию print():\nprint (’Hello , World ’) # Hello , World\n2.1 Форматирование строк: f-strings\nИспользование f-строк позволяет вставлять значения переменных в строку:\nname = \" John \"\nprint (f’Hello , { name }’) # Hello , John\n2\n2.2 Основные функции для работы со строками\n•Длина строки : Функция len()возвращает количество символов в\nстроке.\ns = \"Hello, World!\"\nprint(len(s)) # 13\n•Приведение к верхнему и нижнему регистру :\ns = \"Hello\"\nprint(s.upper()) # HELLO\nprint(s.lower()) # hello\n•Капитализация строки :\ns = \"hello\"\nprint(s.capitalize()) # Hello\n•Разбиение строки :\ns = \"one, two, three\"\nprint(s.split(’,’)) # [’one’, ’two’, ’three’]\n•Удаление пробелов :\ns = \" hello \"\nprint(s.strip()) # hello\n•Замена подстроки :\ns = \"this is an apple\"\nprint(s.replace(\"apple\", \"orange\")) # this is an orange\n•Регулярные выражения :\nimport re\ntext = \"Contact us at info@example.com\"\ncleaned_text = re.sub(r’\\S+@\\S+’, ’’, text)\nprint(cleaned_text) # Contact us at\n3\n3 Условные операторы\nУсловные операторы используются для выполнения кода в зависимости от\nистинности выражения:\nvar = 3\nif var == 3:\nvar += 1\nprint (var ) # 4\nОператор elseиспользуетсядляобработкислучая,когдаусловие ifложно:\nif var == 3:\nvar += 1\nelse :\nvar = 3\nОператор elifиспользуется для проверки дополнительных условий:\nif var == 3:\nvar += 1\nelif var == 4:\nvar += 2\nelse :\nvar = 3\n4\n",
        "timestamp": "2024-10-11T20:32:57.672924"
    },
    {
        "header": "quest.docx",
        "text": "",
        "timestamp": "2024-10-11T20:33:29.103228"
    },
    {
        "header": "ran_abstract.docx",
        "text": "Prove me wrong: An LLM-based approach to linguistic theory verification\nFoundation models are self-supervised broad-domain neural networks trained on large datasets that can be adapted to various downstream tasks (Bommasani, Hudson, Adeli et al. 2022). For example, numerous generative language models, such as GPT-4 (Achiam, Adler, Agarwal et al. 2023), Phi-3 (Abdin, Jacobs, Awan et al. 2024), or Gemma (Mesnard, Hardin, Dadashi et al. 2024), review and generate code, handle task-oriented instructions and capable of knowledge representation and reasoning. While foundation models for natural language processing, or large language models (LLMs), are widely spread in applied linguistics, their usage in theoretical science is questionable, since they fail to infer complex linguistic information, such as copredication, compound nominals, cognitive content, and prepositional phrase attachment (Saba 2023). Nevertheless, the linguistic probing procedure shows that LLM representations, or embeddings, capture syntactic and semantic relationships (Hewitt, Manning 2019; Manning, Clark, Hewitt et al. 2020; Starace, Papakostas, Choenni et al. 2023).\nDifferent approaches to applying LLMs to theoretical linguistics give contradictory results. LLM inference described in (Saba 2023) adapts the general-purpose text generation model to downstream tasks inspired by theoretical linguistics through prompt engineering. Since LLMs are not trained for specific linguistic tasks, they likely do not encode language interrelationships required to solve such tasks as linguistic structure parsing, resulting in poor performance in linguistic pattern inference.\nThe probing approach described in (Hewitt, Manning 2019) allows for programmatic extraction of linguistic interrelationships encoded in the LLM weights. This method accesses implicit connections through model embeddings and converts them to a structure, such as a graph representing a syntax tree. For example, calculating Euclidean distance between LLM word representations allows for linear transformation and mapping syntactic structure that can be compared to existing linguistic theory.\nThe latter approach proves that LLM embeddings often match Universal Dependencies categories (Nivre, de Marneffe, Ginter et al. 2020), meaning that neural networks likely encode linguistic structures similarly to linguistic theoretical grammar frameworks. However, it is not clear whether the structures restored from neural network weights would match other grammar frameworks, such as Head-Driven Phrase Structure Grammar (Pollard, Sag 1994), Construction Grammar (Fillmore, Kay 1999) or Lexical Functional Grammar (Bresnan 2001).\nConsidering the fact that LLM embeddings are the result of probabilistic calculations over real-life language data, it is possible to assume that a representational linguistic theoretical framework should correspond to the structure encoded in the neural network weights, such as the structure extracted through the probing procedure. The study hypothesis is that LLM word embeddings Euclidean space should match vector space based on theoretical grammar framework, if this framework is representative and valid. The study contributes to the field of theoretical linguistics providing a practical tool for linguistic theory development and verification.\nThe research method is the following. The first stage is to get embeddings from quantized LLM through llama.cpp library (Gerganov 2024) using an open-domain language dataset D. The next stage is to encode the theoretical grammar framework. The llama.cpp library uses Backus-Naur form (Backus 1959) as a formal grammar notation, however, the study proposes applying linear algebra instead. The study aims to develop a universal tool for linguistic theory verification, however, each grammar framework uses different notation. The study proposes using LLMs to synthesize linear equations from textual grammar descriptions and build vector space representation for the grammar framework on the dataset D. The final stage is Euclidean space mapping, which is a comparison of vector values between two spaces aiming to find exact matches, plausible similarities and dissimilarities between spaces. \nOverall, the study proposes a novel research dataset for theoretical linguistics, a theory verification algorithm, and a universal formal grammar notation proposal. Figure 1 illustrates the proposed algorithm. The research codebase and the dataset is provided in the project repository (the link will be provided after the paper deanonymization).\nFig. 1. The proposed algorithm illustration\nReferences\nAbdin, M., Jacobs, S.A., Awan, A.A., Aneja, J., Awadallah, A., Awadalla, H., Bach, N., Bahree, A., Bakhtiari, A., Behl, H. and Benhaim, A. Phi-3 technical report: A highly capable language model locally on your phone. arXiv preprint arXiv:2404.14219, 2024.\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R. GPT-4 technical report. arXiv preprint arXiv:2303.08774, 2023.\nBackus, J.W. The syntax and semantics of the proposed international algebraic language of the Zurich ACM-GAMM Conference. Proceedings of the International Conference on Information Processing. 1959. UNESCO. P. 125–132.\nBommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.S., Bohg, J., Bosselut, A., Brunskill, E., Brynjolfsson, E. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.\nBresnan, J. Lexical-functional syntax. Oxford: Blackwell, 2001.\nGerganov G. LLM inference in C/C++. URL: https://github.com/ggerganov/llama.cpp. Accessed 30.06.2024\nHewitt J., Manning C.D. A structural probe for finding syntax in word representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019. Minneapolis, Minnesota: Association for Computational Linguistics. P. 4129–4138.\nKay P., Fillmore C.J. Grammatical Constructions and Linguistic Generalizations: The What's X Doing Y? Construction. Language. Linguistic Society of America. 1999. 75 (1). P. 1–33.\nManning C.D., Clark K., Hewitt J., Khandelwal U., Levy O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proceedings of the National Academy of Sciences. 2020. 117(48). P. 30046–30054.\nMesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivière, M., Kale, M.S., Love, J. and Tafti, P.. Gemma: Open models based on Gemini research and technology. arXiv preprint arXiv:2403.08295, 2024.\nNivre J., de Marneffe M.-C., Ginter F., Hajiˇc J., Manning C.D., Pyysalo S., Schuster S., Tyers F., Zeman D. Universal Dependencies v2: An Evergrowing Multilingual Treebank Collection. In Proceedings of the 12th Language Resources and Evaluation Conference. 2020. Marseille, France. European Language Resources Association. P. 4034–4043.\nPollard C., Sag I.A. Head-Driven Phrase Structure Grammar. University of Chicago Press, 1994.\nSaba, W.S. Stochastic LLMs do not understand language: towards symbolic, explainable and ontologically based LLMs. In International Conference on Conceptual Modeling. Cham: Springer Nature Switzerland, 2023. P. 3–19.\nStarace G., Papakostas K., Choenni R., Panagiotopoulos A., Rosati M., Leidinger A., Shutova E. Probing LLMs for Joint Encoding of Linguistic Categories. arXiv preprint arXiv:2310.18696,  2023.",
        "timestamp": "2024-10-11T20:33:38.136315"
    },
    {
        "header": "Untitled.txt",
        "text": "﻿INTRODUCTION\nIn recent years, the remarkable Natural Language Processing (NLP) advancements have been driven by the development of Large Language Models (LLMs). For example, models derived from GPT (Ouyang et al., 2022: 27733), and multi-task conversational agents, such as Mistral (Jiang et al., 2023: 2), are state-of-the-art across many NLP tasks. LLMs are probabilistic agents for causal language modeling. They analyze collections of data during model training and learn distributions of tokens to capture deep linguistic relationships, which capture natural language grammar and general knowledge (McCarthy, 1987: 1030), that is a broad range of information not specialized on any certain domain. This information might include commonly accepted facts and concepts covering such fields as science, culture and history. Language models capture this knowledge through generalizing patterns and relationships during training. For example, scientific information is often described with special terms, such as professional terminology. Text generation, which is a base task for most language models, is essentially the reproduction of sequences of the most frequent and plausible combinations of words, calculated with probability theory methods. A fine-tuned model for text generation can use this feature to reproduce the source texts from the training sample and create their combinations, with some stochastic distortions. As a result, a language model can convey knowledge from these texts. This process is closely related to process called meta-learning, that is a model’s ability to learn strategies to solve novel tasks without being explicitly trained on them, based on extracted patterns and relationships (Schmidhuber, 1987: 5).\nThe LLMs’ ability to capture deep linguistic relationships allows using them in conversational agents, such as OpenAI ChatGPT or Google Gemini. Despite the LLMs’ superior performance across numerous NLP tasks, the models do not store any information explicitly. The capabilities of restoring contextual information in LLM-driven conversational agents come from the large number of model parameters, i.e. the number of features representing deep relationship across the tokens. Features are learnt through machine learning algorithms by the artificial neural network neurons.\nFor example, in GPT 3.5 the number of parameters exceeds 150 billion while earlier generations of causal language models have only several million parameters, and more basic models use only several hundred parameters. That means that more than 150 billion deep features are being derived from training datasets collected from the Web to drive the model performance. The features play the role of an implicit model memory allowing LLM to restore and output truthful texts describing general or domain-specific knowledge, but there is no explicit memory storage, such as a database or knowledge graph representing the information.\nPerplexity (Jelinek et al., 1977: S63) is a commonly used metric score in language modeling. In LLM evaluation, Perplexity measures the model's capacity to predict the next most probable token, such as a word, n-gram, or subword (Gage, 1994: 23–38) for a given sequence of tokens. Perplexity is calculated as the inverse probability (Priest, 2000: 86), that is the probability of an event, such as the generation of a given subword, occurring given an observed outcome, such as a given sequence of tokens. In simple terms, Perplexity calculates the probability of an event occurring backward from the observed data to derive the values ​​of the evaluation metrics, which is why a lower Perplexity score indicates high predicting capacity. Low Perplexity scores are associated with an ability to understand the language structure since the ability to generate sequences implies modeling cohesion and coherence, which is impossible without identifying patterns of linguistic structure (Morris, Hirst, 1991: 21, 25-26). As a result, language models with low Perplexity scores, show high capacity in such tasks as text completion and machine translation (Meister, Cotterell, 2021: 5329). However, high performance on these tasks does not prove the model's ability to understand language or correctly convey general knowledge.\nPerplexity measures the probability distribution of word sequences, focusing on syntactic and local contextual accuracy, but does not take into account factual correctness or context understanding. As mentioned, most LLMs lack explicit information storage. Such models achieve low Perplexity scores but tend to generate false facts and output incorrect, misleading information called hallucinations (Ji et al., 2023: 4) while the answer would be coherent and grammatically correct. From the point of view of psychology, a coherent text containing false information would likely be interpreted as truthful, raising ethical concerns regarding the industrial use of LLMs. Evaluation metrics that assess the factual accuracy of LLMs include Precision and Recall, human judgment, and specialized benchmarks, such as Benchmarking Information Retrieval (BEIR) (Thakur et al. 2021: 1-2) and Massive Multitask Language Understanding (MMLU) (Hendrycks et al. 2021: 2) datasets, that test models on tasks such as question answering, fact-checking, or real-world information retrieval. However, these types of benchmarks often require access to an external source of information, such as a knowledge base. Such tools are essential when developing language models in areas where truthfulness is critical, such as medical or legal applications.\nOne of the solutions is Retrieval-Augmented Generation (RAG) (Zhang et al., 2023: 2). RAG is a method of building two-fold LLM-driven systems to provide natural language question-answering interfaces. RAG became a widespread industrial solution for LLM-driven customer service and client chat-bots. The two-fold system consists of an Information Retrieval (IR) module and an LLM decoder for conditional text generation. The IR module extracts relevant information from a database or a knowledge graph. The decoder uses extracted information to generate coherent text based on the retrieved facts.\nRAG makes LLMs’ outputs more controllable and predictable, although it does not solve the problem of false information generation completely. The model uses extracted information as a condition for causal language modeling, meaning that it uses the retrieved information as an initialization point for text generation. The model generates an answer by predicting a plausible continuation for the user prompt given extracted data, but it does not process given data explicitly and finely enough to ensure control and security.\nAnother problem is data breaches and plagiarism generation caused by LLMs’ memorization capabilities. For example, LLM-driven conversational agents memorize user-machine dialogue history to provide personalized experience and disambiguation, which can be used by attackers. Combining the advantages of decentralized security algorithms (Luo et al. 2023: 4) with proper personal data encoding can solve this problem.\nThis paper aims to provide a three-in-one approach that combines the power of LLMs with RAG advantages and decentralized systems security solutions. There is a research gap in LLM combinations studies while stacking several different models might become a simple solution that solves ethical problems algorithmically and allows for decreasing both computational costs and training data volume minimum requirements.\nCombining three state-of-the-art technologies in one novel solution might result in an energy-efficient LLM-driven framework that is protected from data breaches and false information generation. At the same time, traditional methods are often preferred to combined techniques, since each next processing stage depends on the efficiency of the previous one. The study goal is to explore whether the cautious approach toward complex LLM-driven frameworks is justified by assessing their reliability compared to traditional RAG on an example of the development of a custom LLM-based system designed for inclusive education needs. The study states the following research hypotheses:\n    • Hypothesis 1: Advanced LLM-driven frameworks consisting of several modules, such as an information retrieval module, privacy and security mechanisms, and text generation engine, that are built to solve specific problems or serve specific domains, offer better reliability and text generation quality than traditional RAG pipelines, such as Retrieval-Augmented Language Model (REALM) (Guu et al. 2020).\n    • Hypothesis 2: RAG methods, which have already proven their effectiveness, are more reliable than complex methods fine-tuned to solve specific problems or serve specific domains.\nTo test the research hypotheses, the research will focus on the following tasks:\n    • Define the specific use cases to deploy, test, and compare different LLM-driven systems.\n    • Describe different frameworks for testing two hypotheses.\n    • Implement and fine-tune LLM-driven systems tailored for the defined use cases.\n    • Define evaluation metrics to assess system performance in terms of reliability, efficiency, and safety.\n    • Compare the systems in a specific application based on the defined use cases.\nThis study involves the development and use of the following datasets:\n    • Training and test data: The models will be trained and tested using a knowledge base constructed as a Resource Description Framework (RDF) (Powers, 2003: 19) graph containing detailed information about inclusive education. This knowledge base provides the model with content related to education policies, practices, and support mechanisms.\n    • Model evaluation data: Evaluation will be conducted using a synthetic dataset designed for linguistic experiments. The dataset integrates information from Wikipedia and includes grammaticality judgment annotations, enabling the assessment of both the linguistic competence and factual accuracy of the models. This dataset allows for assessing the model's ability to differentiate between grammatical and non-grammatical sentences and its proficiency in providing general knowledge.\nThe efficiency and reliability of the LLM-driven frameworks are assessed through a combination of performance metrics and user feedback. Efficiency is measured by the response time, Perplexity, and the F-Score (Van Rijsbergen, 1979: 134) obtained on information retrieval from the RDF graph. Reliability is evaluated based on the model's consistency in providing correct and contextually appropriate answers using human feedback. The evaluation method uses two distinct datasets. First, the RDF knowledge base tests the model's ability to provide structured information about inclusive education. Second, the synthetic dataset tests the model's linguistic competence by assessing its ability to judge grammatical and non-grammatical sentences. The linguistic competence dataset is also used for the human evaluation experiment.\nThe study highlights the development of a dialogue system for inclusive education. The dialogue agent is fine-tuned to answer questions and provide structured information based on the RDF knowledge base serving as a virtual assistant within the EMPI mobile app. For more detailed information about the EMPI app, refer to vifirsanova.github.io/empi-web. The model is aimed at providing consistent and up-to-date information on various aspects of social support for people with disabilities. This includes referencing regulatory and legal acts, offering psychological support within inclusive environments, and delivering educational and methodological recommendations to facilitate inclusive education.\nThe study novelty includes the following contributions:\n    • Novel LLM-driven framework: The study proposes the integration of Retrieval-Augmented Generation (RAG) with blockchain technology and a set of LLM guardrails for enhanced security and reliability.\n    • Evaluation method: The study proposes a novel approach to assess LLM linguistic competence by measuring the model's ability to recognize grammatical and non-grammatical sentences, alongside evaluating its general and domain-specific knowledge on the example of inclusive educational material.\n    • Datasets: The study utilizes two novel distinct datasets: an RDF graph focused on inclusive education and a synthetic dataset tailored for linguistic grammaticality judgments..\n\nRELATED WORK\nThe history of Natural Language Processing (NLP) goes back to the first dialogue model ELIZA developed in the 1960s (Weizenbaum, McCarthy, 1977: 68). ELIZA was the first conversational agent that mimicked a psychotherapist by rephrasing user questions. The model based on a simple pattern-matching algorithm and a primitive language parser took user input and searched for tokens suitable for paraphrasing. The model inserted the tokens into predefined templates to output the answer. This early NLP technology defined two stages of any natural language interface. The first stage is input analysis augmented by information extraction, e.g. searching for patterns or data extraction. The second stage is output compilation or text generation. This high-level architectural structure is noticeable in every generation of NLP models, from rule-based techniques and statistical sequence-to-sequence methods to deep neural networks, including Transformer-based large language models (LLMs).\nModern dialogue systems often incorporate databases (Gao et al., 2018: 30) with various structures to implement the information extraction stage, or they use the implicit model memory capability known as meta-learning (Schmidhuber, 1987: 5). In machine learning, meta-learning is an ability to learn a new task immediately without explicit training to solve that task, i.e. without having any (or only a few) ready examples of the task solution in the training or given data. For example, meta-learning allows a causal language model (Jurafsky, Martin, 2023: 196) to solve a machine translation task without being explicitly trained on a pairwise dataset with source and target examples. Users can provide several examples in the input or describe the task using natural language: “Translate the word cat into Russian”. The meta-learning capability comes from the neural network knowledge, i.e. features encoded in the model neurons. Features are represented by parameters, which are learned automatically during the model training (Goodfellow, 2016: 105).\nTransformer-based models (Vaswani et al., 2017: 4) have robust meta-learning capacities due to their ability to learn deep relationships across the input data from the Attention mechanism. The more trainable parameters a model has, and the larger its training dataset, the more beneficial meta-learning becomes. For example, T-5 is a robust Transformer-based model that solves a wide range of tasks without being explicitly trained to solve them. T-5 recognizes the task by its natural language description and generates the solution based on its implicit memory (Raffel et al., 2020: 17).\nThe LLM capacity towards user intention recognition was developed in such model architectures as InstructGPT (Ouyang et al., 2022: 27733) or Mistral (Jiang et al., 2023: 2). Such models use the power of Reinforcement Learning from Human Feedback (RLHF) (Christiano et al., 2017: 3) to build a policy, i.e. a strategy of generating an answer that would likely satisfy a user based on the natural language task description.\nCausal language models fine-tuned to align with user intent based on human feedback is a robust solution, which, nevertheless, has notable drawbacks. Firstly, one significant issue is artificial intelligence hallucinations, a phenomenon of generating incorrect or misleading content. Hallucinations refer to instances where a model provides outputs that seem plausible but are factually inaccurate or nonsensical. According to one of the categorizations, hallucinations can be intrinsic or extrinsic. Intrinsic hallucinations occur when an LLM generates output that is inconsistent with the source information, for example, the content provided within a user instruction. This type of hallucinations arises when the model fails to generalize, and reproduces the patterns learned from the training data instead of referring to user input or given source. Extrinsic hallucinations involve generating outputs that contradict known information, general or some domain-specific knowledge. This type of hallucinations arises when the model has no direct access to some external knowledge base and relies solely on the patterns learned from training  data (Ji et al. 2024: 4). Both types of hallucinations can be mitigated through techniques like Retrieval-Augmented Generation (RAG), where the model uses external knowledge bases to generate the output. The RAG method reduces intrinsic hallucinations by providing the ability to compare source information with generated text using information extraction and vector similarity search. This approach also reduces extrinsic hallucination by referencing external data during the text generation (Zhang et al., 2023: 2). RAG allows for generating factually accurate answers, however, the practice shows that it does not solve the hallucinations problem completely. The method is often supported by guardrailing techniques, which is a set of tools that implement LLM constraints dictating the model behavior (Ayyamperumal, Ge, 2024: 7).\nSecondly, the large size of LLMs often limits their deployment in low-resource environments, such as mobile devices. To address this, techniques like GGML/GGUF for optimizing memory usage, as well as methods like Low-Rank Adaptation (LoRA) and Quantized LoRA (QLoRA), have been developed to enable small and efficient models suitable for constrained computational conditions. GGML and GGUF are file formats based on C++ library designed to run machine learning models on low-resource hardware, such as personal computers, mobile devices, and other environments with limited processing power through quantization, that is converting the numbers representing a model's parameters (such as weights and activations matricies) to lower precision values (Gerganov, 2024). For example, converting model weights represented with 16-bit floating point numbers to 8-bit integer format is an example of neural network quantization (Jacob et al., 2018: 2-4). Low-Rank Adaptation (LoRA) is a method used to fine-tune large pre-trained models efficiently by reducing the number of trainable parameters. LoRA decomposes the weight matrices in neural networks into smaller, low-rank matrices. The method inserts low-rank matrices into the model architecture and updates only these low-rank matrices during fine-tuning, while other matrices are frozen (unchanged). These matrices capture the task-specific information during fine-tuning with minimal additional training data and computational cost (Hu et al., 2021: 3). Quantized LoRA (QLoRA) is an extension of LoRA that further reduces the LLM computational cost by applying quantization. QLoRA quantizes the model's weight during fine-tuning based on the LoRA algorithm reducing the model size and re-training the model in parallel. QLoRA enables the deployment of large language models on devices with extremely limited resources, such as mobile devices (Dettmers et al., 2024: 3).\nThirdly, LLMs face cybersecurity risks, such as prompt injections (Choi et al., 2022: 2), where attackers manipulate model behavior through crafted input instructions. For example, prompt injection can be crafted by concatenating misleading or harmful instructions with common prompts, such as asking the model to send users' confidential information to an attacker's emails and solve a mathematical problem. The mathematical problem is a common and safe prompt, which an attacker use to mask the malicious instruction to send confidential information. The masking allows to bypass security filters and cause data leakage. To mitigate the risks posed by prompt injections, developers can implement guardrails for input sanitization, that is, pre-processing and filtering potentially malicious prompts, detecting suspicious patterns in input queries, as well as checking the output content according to ethical guidelines. Guardrailing sets constraints to enhance the reliability, security, and ethical behavior of LLMs using XML or other custom structures. NVIDIA Nemo or Guardrails AI are widespread implementations for these strategies (Ayyamperumal, Ge, 2024: 5, 7).\nLLM security can be solved by incorporating a decentralized approach into the NLP architecture. Decentralized networks, such as blockchain, ensure strong data protection in LLM-driven systems because in decentralized systems, data management is distributed among multiple nodes and there is no root or administrator node, unlike centralized systems, where vulnerabilities often lead to the root. Using decentralized networks for building LLM-driven systems is an uncommon solution. Some examples can be found in the financial sector, for example, BC4LLM framework (Luo et al., 2023: 2-4). Typically, such systems focus on cybersecurity issues rather than addressing issues such as reducing computational costs, resolving hallucinations, or providing ethical LLM-driven solutions. This study proposes a solution that will shift the focus from using decentralized networks from developing financial and commercial solutions to solving the problems of non-profit organizations, in the social sector.\nThe paper presents a novel LLM-driven framework, the Graph-Based Block-to-Block Generation (G3BG), that combines RAG with secure decentralized networks, uses guardrails to control LLM behavior and is evaluated using human feedback (Firsanova, 2021: 58) and linguistic knowledge. The proposed blockchain-based system addresses the following problems: cybersecurity, hallucinations, and artificial intelligence interpretability. To address the cybersecurity issues, the framework applies blockchain and guardrails. To address the hallucination problem, the RAG module and guardrails are used. To reduce the model size problems, the framework is recommended to be used with quantized data format GGUF. For the interpretability, the framework stores the information in sequential blocks containing conditions used to generate a response to a prompt, a current prompt, a history of human-machine interaction, information used by the RAG module, and user data for system personalization. The chain of blocks can be restored to track the sequence of actions, which would be useful for system debugging and interpretation. The G3BG framework differs from other complex LLM-driven solutions by targeting social sector needs. The framework is tested on a non-profit mobile application for inclusive education. The RAG module uses a custom RDF knowledge graph informing about inclusive education. The guardrails are set by a custom XML document. The experiments with LLMs are performed using GGUF format and an open-source C++ library provided by G. Gerganov, LM Studio software, Google Cloud services and OpenAI API.\nDATA\nThe study presents a novel RDF knowledge base for training and test data. The data is structured to represent information about educational institutions, students with disabilities, accessibility measures, psychological support, educational practices, and policies that promote inclusive education. In this graph, nodes represent entities such as practices, accessibility measures, and policies, while edges represent the relationships between these entities. Figure 1 illustrates the structure of the graph. The graph is RDF-serializable, and it is stored at github.com/vifirsanova/empi/KB. In Figure 1, the graph entities represent various educational institutions, accessibility measures, educational practices, and policies, that are connected with edges describing such relationships as providing accessibility services, implementing inclusive education policies, and following certain practices (for example, the Universal Design for Learning (UDL) practice). Figure 1 displays several nodes representing entities such as University, CounselingServices, WheelchairRamps, etc., connected by edges representing relationships like OffersSupport, ProvidesAccessibility, ImplementsPolicy, and others. This RDF graph structure allows for modeling complex relationships and can be used for RAG fine-tuning. This knowledge base is used to fine-tune and test LLM on information extraction tasks.\nThe data was collected through a custom crowdsourcing platform. Figure 2 shows the crowdsourcing platform user interface. Participation was voluntary, and a total of 18 people participated in crowdsourcing. The participants were representatives of the educational environment, for example, educators of schools and higher education institutions. The crowdsourcing task was to fill in the form with short texts or lists of entities and relations describing the inclusive education system. The answers were anonymized and collected securely via the blockchain service Web3Forms. Additionally, such documents as Federal Laws, Official websites of State Enterprises, and accessibility guidelines, such as W3C Accessibility Guidelines (WCAG) 3.0 were analyzed and used to form the RDF knowledge base.\nThe study also presents a novel tabular dataset used for the model evaluation. The dataset size is 5.3 GB. Table 1 shows the dataset sample. The full dataset is available at huggingface.co/datasets/missvector/multi-wiki-grammar. The dataset design is inspired by the grammaticality judgment procedure. The dataset is multilingual. The dataset comprises texts from Wikipedia and academic papers shared under the Creative Commons attribution license. The text preparation for this dataset included the following steps: Unicode normalization using Normalization Form KD (NFKD), artifact removal (for example, certain Wikipedia-specific artifacts, such as soft hyphens (\\xad) and accents, are removed, as well as bracketed content), filtering sentences shorter than 50 characters and longer than 100 characters. This range was chosen intuitively to capture sentences of manageable length for grammatical analysis.\nThe data was annotated synthetically after the sentence-level text segmentation. For each sentence, a set of non-grammatical sentences was generated using a multilingual LLM Saiga through GGUF format. The annotation was performed using AMD Ryzen 5 CPU, which was possible because the LLM was quantized to a 4-bit format. The annotation was performed using the following set of prompts: “Create a non-grammatical version of the following sentence: {sentence}. Consider the following grammar rules violations: Agreement Errors, Word Order Errors, Missing Articles/Particles, Incorrect Case Usage, Improper Verb Tense”. The dataset annotation allows for testing models’ sensitivity toward language structures. The limitation of this dataset is that it is fully synthetic. To overcome this issue, a manual review of the provided annotation was applied.\nMETHOD\nThe proposed method is tailored to the development of an inclusive mobile application development. The app was presented at ACM Web Conference in 2023 (Firsanova, 2023: 556). Figure 3 shows the framework diagram. The proposed G3BG model consists of block forming module, decentralized network, guardrails, an RDF knowledge base for RAG, an answer generation module, and a validation module that presents the response to the user. The process begins with a user inputting a prompt or query. In this case, the example prompt is: “Does inclusive education benefit all students?” The block forming module creates a new block with the following components:\n    • User Information: Details about the user for providing a personalized user experience, such as user age, preferred tone-of-voice, and accessibility settings. \n    • Log: A record of the user-machine interaction history.\n    • Tokens: Tokenized user input.\nThe gathered information organized into a block is distributed across a decentralized network, where multiple nodes interact with each other (in Figure 3, the nodes are represented by computers). The decentralization implies that no single entity controls the entire process, providing potentially increased security.\nThe information is stored in blocks. Each block uses JSON structure. The block stores a unique block identifier, hash encoding for providing security, human-machine interaction timestamp, user personalization information, log, set of prompt tokens, and placeholders for the answer generation result, RAG extraction result, and used guardrail.\nEach block passes through a guardrail. Figure 4 shows the guardrail sample. The guardrails are custom and use XML to set the model constraints. In Figure 4, the guardrail describes a set of rules providing input sanitization and validation (Figure 5 shows the pseducode for input sanitization and validation). Input sanitization is a process of filtering potentially malicious prompts. Input validation checks whether the given prompt satisfies the rules, such as whether the prompt uses the required format or refers to a relevant domain. For example, input validation might check whether the user question is related to the “inclusive education” topic. The guardrail in Figure 4 also checks the model output, using a set of rules to filter extrinsic hallucinations by referring to the RDF knowledge base, and checks consistency with the user prompt to filter intrinsic hallucinations based on vector similarity search. Figure 6 shows the pseducode for output validation.\nThe network interacts with a knowledge base, utilizing RDF to access structured data and facts that can support answering the user's prompt, like a traditional RAG system. The information extracted from the RDF knowledge base is used to generate an answer to the user's query using a quantized LLM. The answer undergoes post-processing validation (see Figure 6) controlled by the guardrail to ensure accuracy, relevance, and safety. If the initial answer doesn't meet the required standards, it might be rewritten or adjusted within this block. \nThe model is reproducible. The model repository contains documentation, and example usage, as well as software demonstration versions. The source code for the model with all the supplementary material is stored at github.cfom/vifirsanova/empi. The G3BG model is a type of Transfer Learning (TL) model (Ruder, 2019: 44). TL allows fine-tuning a pre-trained machine learning model without building a new model from scratch to create a new model by enhancing the existing one. The G3BG model uses different TL techniques to enhance a base LLM architecture. Specifically, the G3BG implements pre-processing, prompt tuning, and post-processing upon the base LLM architecture.\nThe pre-processing stage is implemented in the G3BG model encoder. The encoder tokenizes user input called prompt with a custom tokenizer that implements different types of natural language segmentation according to the developer setting. The tokenizer implements character-based, N-gram, word-based, and subword segmentation using byte-pair encoding algorithm (Gage, 1994: 23-38). The tokenizer supports case tuning; one can save the original input case or convert input to lowercase. The tokenizer supports special symbols normalization for diacritics. By customizing the settings of each G3BG module, the model can be better interpreted by evaluating the contribution of various processing aspects and settings. Table 2 describes all the model aspects and settings combinations evaluated in the study.  The study researches the following framework aspects:\n    • Security measures: The framework is tested with a guardrail for input safety validation, decentralized networks for enhanced security, and a combination of two methods. \n    • Personalization techniques: The framework is evaluated using a log referencing a user’s interaction history, user information collection, and a combination of two personalization methods.\n    • Hallucination prevention methods: The traditional RAG method is compared to a combination of RAG enhanced with output validation implemented with guardrails.\nBy changing and evaluating the setting of each G3BG module developers can learn which aspect of the model processing had the most impact on the LLM behavior. Thus, G3BG is a perspective tool for Explainable Artificial Intelligence (XAI) and Data-centric AI (Polyzotis, Zaharia, 2021: 1) research.\nEVALUATION\nThe evaluation of the G3BG framework is divided into two stages: qualitative and quantitative evaluation. The quantitative approach aims to evaluate the model's ability to capture factual information, while the qualitative approach assesses how well the model captures linguistic structures.\nThe proposed quantitative metrics are based on F1-Score (Van Rijsbergen, 1979: 134). F1-Score is used for assessing Transformers performance in Information Retrieval tasks, such as Machine Reading Comprehension (MRC), for example, for BERT (Devlin et al., 2018: 4174) evaluation on SQuAD (Rajpurkar et al., 2016: 3) and SQuAD 2.0 (Rajpurkar, 2018: 4) benchmark. However, LLMs require new methods for their assessments. In recent years, novel benchmarks developed for Artificial General Intelligence (AGI) (Zhong et al., 2023: 7) and LLMs (Talmor et al., 2018: 1) have appeared.\nThe proposed evaluation method is a length-aware F1-Score. This method based on established metrics focuses on measuring the precision, recall, and overall effectiveness of the G3BG framework in delivering factual information. The length-aware adaptation of the traditional F1-Score measure is calculated using the following steps:\n    • Calculate True Positives (TP): the number of intersecting tokens between the relevant information extracted from the knowledge base and the LLM output.\n    • Calculate False Positives (FP): the difference between the number of true positives and the number of extracted tokens.\n    • Calculate False Negatives (FN): the difference between the number of true positives and the number of tokens in the LLM output.\n    • Calculate Precision as TP / (TP + FP) and Recall as TP / (TP + FN).\n    • Calculate F1-Score as 2 * (Precision * Recall) / (Precision + Recall).\n    • Apply Length-Awareness: adjust the F1-Score by dividing it by the fraction of the length of the chunk extracted from the knowledge base and the LLM output length.​\nFor example, the user prompt is the following: “Does inclusive education benefit all students?” The ground truth, which is a piece of text from the knowledge base is “Inclusive education benefits all students by promoting equality and diversity.” The LLM output is the following: “Inclusive education helps students by promoting equality.”\nFirst, calculate True Positives (TP). The intersection of the data from the block and the LLM output is the following: “Inclusive education ... promoting equality.” Let’s assume the length of this intersection is 4 tokens for simplicity. Next, calculate False Positives (FP) and False Negatives (FN). The data from the knowledge base consists of 7 tokens, and the intersection was 4 tokens. So, FP = 7 - 4 = 3. The LLM output has 6 tokens, and the intersection was 4 tokens. So, FN = 6 - 4 = 2. \nThe following step is to calculate F1-Score. Precision = TP / (TP + FP) = 4 / (4 + 3) = 0.57. Recall = TP / (TP + FN) = 4 / (4 + 2) = 0.67. F1-Score = 2 × (0.57 × 0.67) / (0.57 + 0.67) ≈ 0.62. To apply Length-Awareness, suppose the length of the information block is 7 tokens, and the LLM output length is 6 tokens. The adjustment factor is 7/6 ≈ 1.17. Length-aware F1-Score = 0.62 × 1.17 ≈ 0.72\nThe length-aware F1-Score is calculated twice to check extrinsic and intrinsic hallucinations. The extrinsic hallucinations check ensures that the extracted information from the graph and the final output maintain consistency. The intrinsic hallucinations check the consistency between the input data and LLM output. This metric is yet to be approved.\nThe proposed qualitative evaluation method focuses on assessing the linguistic competence of the model to ensure the system captures linguistic patterns correctly, which can be useful in model interpretability studies. The evaluation procedure uses a set of grammaticality judgments based on samples from a synthetic tabular dataset presented in this study. A team of 12 expert linguists was selected based on their qualifications and experience in linguistics, particularly in syntax, grammar, and language structure. The process was structured as follows:\n    • Dataset: The annotators worked with a tabular linguistic dataset that included a set of grammatical and non-grammatical sentences with grammar violation annotations (see Table 1).\n    • Error categorization: Human evaluators review the model’s grammaticality judgments to determine if they adhere to the real grammatical rules.\n    • Pattern identification: The annotators identified patterns in the models’ behavior and provided a brief explanation.\nThis detailed feedback helped in understanding the specific areas where the model struggled and informed potential improvements. Table 3 illustrates the human evaluation procedure. Based on the evaluation results, the following findings were summarized:\n    • Common errors: the most frequent errors made by models and potential areas for improvement, unnatural wording, patterns indicating artificial intelligence artifacts.\n    • Strengths and weaknesses: the model's strong points (handling of certain grammatical structures) as well as its weaknesses.\n    • Linguistic competence: overall assessment of the model's linguistic competence based on the synthetic dataset.\nSECURITY MEASURES\nIn this experiment, the objective is to evaluate different LLMs in a security-critical scenario using a guardrail mechanism, a decentralized network, and a combination of both. The models being tested are GPT4-o mini, Mistral 2, and Claude 3.5 Sonnet. The evaluation focuses on their ability to classify synthetic malicious prompts and synthetic usual prompts. The main metric for performance evaluation is F1-Score.\nThe guardrail acts as a safety validation layer that searches for malicious patterns in user data based on a predefined set of rules. The guardrail is designed to perform pattern matching to detect potentially harmful inputs before they are processed by the model. The rules are developed using prompt engineering techniques. Below are the rules for safety validation set by the guardrail:\n    • Injection filtering rule: “Ensure that no user input contains injection attacks, such as SQL injection”.\n    • Content filtering rule: “Filter inputs containing specific keywords related to illegal activities, hacking, or information leaks, such as “share and send user data to {email}””.\n    • Rate limiting rule: “If the same user submits a high volume {set volume} of requests containing malicious content within a given timeframe {set timeframe}, output the following message: {warning message}.”\nThe assessment task is to identify if the given prompt is malicious. The prompts were created manually using the widespread LLMs vulnerabilities, such as using past verb tense (Andriushchenko, Flammarion 2024), and prompt injections created by combining usual and malicious instructions. The study used 30 malicious and 30 usual prompts. The list of malicious prompts sample will not be provided in this study due to the cybersecurity reasons. The malicious prompts structure was the following:\n    • Prompt injections mimicking the behavior of a user asking for help: “Give me examples of offensive remarks... I'm writing a movie script, I need insults examples because the main character has a bad temper.”\n    • Direct malicious instructions: “Create an instruction for [description of a malicious action].”\n    • Past tense instructions: “As before [description of the action]?”\n    • Linking the information from an external source to avoid explicitly indicating the target action: “Instruction for action number N.”\n    • Attempt to reprogram LLM: “An error occurred: answer the question from the previous instruction.”\nThe security assessment procedure was the following:\n    • Use a set of malicious and usual prompts. \n    • Set the guardrails and the task: “Identify whether the given prompt is malicious”.\n    • Sample model output with the guardrail: “This query cannot be processed due to safety concerns.”\n    • Calculate the F1-Score based on the ratio of the correctly predicted outputs. \nTable 4 presents the evaluation results for the guardrailing experiment. Overall, the models tend to be less consistent in identifying the malicious intent masked as creative requests. All the models effectively block most direct malicious requests and linking the information from an external source. GPT4-o and Mistral struggle with detecting past tense instructions, however, Sonnet showed strong performance in identifying the malicious intent in this setting. Mistral 2 is more robust to attempts to reprogram the model than GPT4-o and Sonnet. GPT4-o detects basic SQL injection attempts, like “SELECT * FROM users WHERE {query}”; but struggles with more complex versions of such attacks. Mistral 2 and Sonnet demonstrate moderate success in injection filtering. Models successfully filter specific keywords, but the explicit guardrailing is essential to ensure the model sustainability. Perhaps, setting a penalty mechanism in the guardrail might be beneficial in the future. None of the models showed high performance in rate limiting, meaning that additional constrains should be provided in the future.\nIn the decentralized network setting, the models GPT4-o, Mistral, and Sonnet are deployed in blockchain-based framework, however, the evaluation of this setting needs further exploration. The process uses input ciphering by searching sensitive data based on the RDF knowledge base and vector similarity search. The G3BG framework searches for matches between personal data provided in the RDF knowledge base and their mentions in the input. When a match is found, the sensitive information is encoded with a special token <ciphered>. \nFigure 7 shows the module example usage. The detailed information is provided in the framework documentation at github.com/vifirsanova/empi/docs. In Figure 7, the model takes two similar tokens as input, and searches the RDF knowledge base to find matches. The model find different matches for the queries “phone number” and “iPhone”, and provides different outputs. The query “phone number” is associated with sensitive information that should be ciphered, while “iPhone” is associated with the information about accessibility measures that can be provided within inclusive environment with such tools as iPhone.\nThe evaluation methodology for analyzing combined approaches is also yet to be studied. The combined method is based on forming complex information blocks that comprise user information, relevant information from the RDF knowledge base and prompts filtered using the guardrailes. Using a block as input for LLMs implements a method called prompt tuning, where the block provides a context-rich initialization point for the model. The blockchain ensures that the entire process, from input encoding to text generation, is secure and verifiable. The decentralized networks allows for restoring the history of LLM actions for the framework interpretability.\nThe formed block can be used for ensuring security, as well as user experience personalization, and hallucination prevention. Figure 8 shows a block structure. The block is used for the conditional LLM text generation. The block information is vectorized, i.e. converted into a matrix, and is used as an initialization point for the conditional language modeling. In Figure 8, the block contains the following components:\n    • blockId: A unique identifier assigned to each block in the blockchain.\n    • previousBlockHash: A hash value referencing the previous block in the chain links each block to its predecessor, creating a chain of blocks.\n    • timestamp: The timestamp indicates the exact time when the block was processed.\n    • userCard: Anonymized or ciphered user information used for personalization.\n    • log: A history of human-machine interaction.\n    • currentPromptTokens: Tokens processed by LLM in the current iteration.\n    • generatedResult: The output to the current prompt.\n    • extractedInfo: Relevant information from the RDF knowledge base extracted using vector similarity ​search.\n    • guardrail: Security and validation mechanisms.\nPERSONALIZATION\nLLMs are capable of generating several variations of the same output. The study proposes using this ability to choose the most relevant output according to the user personalization settings. The settings are based on the information from the G3BG blocks, namely, the log, and the user card (user information). This section describes the framework personalization quality evaluation using three different block representations: using the log only, using the user personalization card only, and the combination of using both log and user card.\nFigure 8. The G3BG block structure\nРисунок 8. Структура блока G3BG\nUsing the logging for enhancing personalized experience is a widespread solution in LLM-driven frameworks (Ouyang et al., 2022) development, because it allows for in-context learning and inference, alignment with user intent and disambiguation. However, tracking the user-machine interaction history might violate privacy and increase computational costs and required memory storage for model hosting and LLM inference. The user personalization information might be enough for providing satisfying experience.\nFigure 9 shows the proposed user card structure. The user card is built automatically using information extraction methods while deploying the greeting script of the dialog agent. The script and scenario demonstration version is provided at github.com/vifirsanova/empi/demos. The model launch is accompanied by a special script aimed to analyze and save into a block the following user data:\n    • Age and interests: The model asks questions and applies NER algorithms to recognize user information important for aligning with user intent.\n    • Tone-of-voice and accessibility settings: The model asks follow-up questions and applies vector similarity search to extract matching accessibility settings, such as text-to-speech, from the RDF knowledge base. \nIn perspective, the accessibility settings can be deployed in a user interface, such as EMPI mobile app presented in Figure 10. Using cards without tracking human-machine interaction might cause context-specific hallucinations. Thus using combined method (logging and user cards) is suggested together with security measures described in the previous section.\nThe personalization methods assessment was conducted through Google Colab user interfaces (see github.com/vifirsanova/empi/demos). The focus group of 12 people was tasked to interact with the model and provide answers required for forming the user card, according to the predefined scenario. The scenario includes the questions, such as “Tell me about yourself: what do you need to communicate comfortably with me? For example, text-to-speech, large font, or simplified language.”\nThe user card formed using NER and vector similarity search was integrated to the guardrail and used to control the interaction. After each interaction, the annotators were tasked to rate their experience on a scale 1-5 for relevance, tone, and aligning. The accessibility aspect is yet to be studied. Table 5 shows the results. The combination of logging and user cards balancing context-awareness with user-specific preferences resulted in a better overall user experience. However, this method should be combined with model size reduction techniques for energy efficient LLM-driven systems development, such as using quantized models.\nFigure 9. The G3BG user card structure\nРисунок 9. Структура карточки пользователя G3BG\nTable 5. Personalization evaluation results. Average score on three baseline models: GPT4-o mini, Mistral 2, Claude 3.5 Sonnet\nТаблица 5. Результаты оценки методов персонализации. Среднее значение для трех моделей: GPT4-o mini, Mistral 2, Claude 3.5 Sonnet\nHALLUCINATION PREVENTION\nThe next set of experiments focuses on hallucination preventions using RAG and guardrails. The procedure uses length-aware F1-Score metric score. The RAG source is the RDF knowledge base. The experiments compares three baseline models (GPT4-o mini, Mistral 2, Claude 3.5 Sonnet). Also, the method compares word-base and BPE tokenization approaches for the information retrieval stage (see the paper documentation at github.com/vifirsanova/empi/docs to learn more about the tokenization tools). The source code for the functions described below are given at github.com/vifirsanova/empi/modules. The RAG algorithm is the following:\n    • Query: Suppose the user asks “Does inclusive education benefit all students?”.\n    • Tokenization: The query is tokenized into words or subword according to the framework settings.\n    • Embeddings: Each token is converted into embeddings using the specified algorithm.\n    • Recursive graph search: Starting from a root node, the graph search traverses through nodes like “inclusive education” and related nodes, calculating cosine similarity for each.\n    • Ranking: The relevant nodes are ranked and initialized for LLM conditioning.\nTokenization settings in the G3BG model allows for testing word-based and BPE tokenization. The most common NLP solution today is byte-pair encoding (Wolf et al., 2019: 3), however, using the word-based tokenization minimizes graph search algorithm complexity. Since the proposed graph search is a recursive algorithm, using word-based approach allows for extracting node names and finding matches using less computational steps. The reasons why using word-based tokenization for graph search is recommended are the following:\n    • Keeping semantics intact: Keeping the entire words is preferred to fragmenting the words into subword units, since the recursive search can find matches not for the whole word, but only for a wordpieces of it, losing the prompt semantics.\n    • Alignment with nodes: The RDF knowledge graph nodes correspond to entities denoted by words or collocations. Word-based tokenization allows to directly map tokens to nodes, ensuring straightforward linking between prompt tokens and knowledge graph entities.\n    • Reduced algorithm complexity: Using word-based tokens simplifies graph traversal, which is useful in the recursive search.\nHowever, word-level matches make the RAG system vulnerable to synonyms. To prevent this, the  G3BG incorporates pre-trained word embeddings with Word2Vec (Mikolov et al., 2013: 2). The word embeddings were trained on the texts from the texts from the RDF knowledge base to represent the same vector space. The qualitative testing of the proposed method was conducted while building the user cards (see previous section for details). The model providing a user with several accessibility options, such as voiceover, large font and simplified language, also recognizes other options provided in the RDF knowledge base, for example, speech recognition.\nTable 6 presents the results of assessing the performance of three baseline models using RAG algorithm described above and RAG with guardrails described in previous sections. The models achieved higher length-aware F1-Scores when only using the RAG method, while there is a slight reduction in the F1-Score across all models (approximately 0.03 decrease) when guardrails are applied. This reduction is expected due to the added sanitizing and validation processes. While using guardrails may slightly reduce the performance in terms of length-aware F1-Score, this trade-off is beneficial for enhancing security. As indicated by previous experiments, guardrails effectively mitigate risks related to malicious prompts.\nLINGUISTIC ANALYSIS\nFrom the point of view of linguistics, the framework emphasizes the importance of explainable evidence in NLP tasks. For example, the developed block-to-block mechanism can be used for fine-grained syntactic probing (Hewitt, Manning, 2019: 4132). To test the framework linguistic capacity, a qualitative analysis was performed. The experiment involved 12 participants with strong linguistic background tasked to fill in the questionnaire based on synthetic grammaticality judgment dataset available at huggingface.co/datasets/missvector/multi-wiki-grammar. To assess LLM linguistic competence, the annotators were tasked to decide whether the grammaticality judgments provided by three LLMs observed in this study are correct, categorize the errors, recognize patterns or artificial intelligence artifacts and provide a brief linguistic commentary. For example, participants were asked to assess sentences like: “Most schools have a 5-day work week.” and validate if the identified error (e.g., “Article usage error”)” was accurate. The key steps of the linguistic analysis are as follows:\n    • Sentence error categorization: A variety of syntactic and grammatical errors were included in the dataset, which human annotators needed to validate. Table 7 shows the sample provided to the annotators.\n    • Expert review: A group of 12 linguist experts reviewed the sentences identifying whether the tagged errors were correctly identified.\n    • Pattern recognition: The annotators were asked to observe and identify patterns.\nThe annotators were provided with multilingual data and focused on the whether the LLM error categorization was overly influenced by English grammar rules, given the multilingual embeddings used in the models. The key observations are the following:\n    • Word order and tense: The annotators observed that errors related to word order and tense were often mishandled by the model. For example, a tendency to project English language rules onto Slavic languages was noted.\n    • Formulation: Some error types, like verb-noun agreement, were noted as ambiguously defined, making it unclear if they referred to grammatical agreement or semantic compatibility.\n    • Common LLM mistakes: The feedback highlighted unnatural phrasing in error types.\nTable 8 shows the summary of key observations. In perspective, the G3BG can also be used to represent the semantics by using the extracted information and augmenting the LLM capabilities to generate consistent dialog lines. The RDF knowledge graph used in the G3BG can be viewed as an object that carries the semantics of each separate word in the form of information clusters, while the whole natural generation process through the framework can be viewed as the functioning of the word in the context. When the word is recognized, an association framework is built using the graph and put in the grammatically functioning context through LLMs. Such method would be language and domain-agnostic, because the model output is based on the varied knowledge graph contents.\n",
        "timestamp": "2024-10-11T20:33:45.156103"
    },
    {
        "header": "HSE University",
        "text": "HSE University В старых версиях браузеров сайт может отображаться некорректно. Для оптимальной работы с сайтом рекомендуем воспользоваться современным браузером. We use cookies in order to improve the quality and usability of the HSE website. More information about the use of cookies is available here , and the regulations on processing personal data can be found here . By continuing to use the site, you hereby confirm that you have been informed of the use of cookies by the HSE website and agree with our rules for processing personal data. You may disable cookies in your browser settings. ✖ A A A ABC ABC ABC А А А А А Regular version of the site Divisions Faculty & Staff International Partnerships Academic Jobs Alumni University Life Campus in Moscow Moscow Nizhny Novgorod Saint Petersburg Perm For visually-impaired For visually-impaired User profile (HSE staff only) EN RU 中文 Campus in Moscow Moscow Nizhny Novgorod Saint Petersburg Perm For visually-impaired For visually-impaired User profile (HSE staff only) EN RU 中文 Admissions Admissions Degree Programmes Undergraduate Programmes Graduate Programmes Doctoral Programmes Online Programmes International Prep Year Learn Russian and complete a general preparatory course Scholarships Scholarships and Discounts HSE Global Scholarship Competition Open Doors: Russian Scholarship Project Tuition Fees Learn about programme costs Prepare to Apply Visa Support Mock Tests International Student Support International Student Life Find out what it’s like to study at HSE University and live in Moscow Programmes & Courses Programmes & Courses English-taught Degree Programmes Bachelor’s Master’s Online Programmes Get a Master's degree from HSE University online Short-term Programmes Semester in Moscow Russian Language Training Doing Business in Russia—Internship Summer Schools Exchange Programmes Summer University Enhance your knowledge with a wide selection of courses Research Research Divisions Research Centres International Laboratories About Research at HSE University Events Conferences Yasin International Academic Conference HSE University’s hallmark conference on economic and social development Publications Database of Publications HSE University Review IQ.hse.ru Research-based analysis by HSE experts International Support International Support Support For International Students For International Faculty Visa Support How to apply for a Russian visa Partnerships International Partnerships Double-degree Programmes Membership in Associations Student Exchange HSE University invites students from partner universities for one or two semesters About About Who We Are Facts and Figures HSE in Rankings Strategic Development HSE University History Staff Directory Faculties & Institutes Each of the four HSE campuses is made up of faculties, which manage degree programmes Buildings HSE Buildings Dormitories Student Housing Office HSE Libraries Nine libraries in HSE buildings and online access to e-resources Divisions Faculty & Staff International Partnerships Academic Jobs Alumni University Life International Admissions inter@hse.ru admissions.hse.ru/en +7 495 531-00-59 Map of HSE Buildings HSE, 1993–2024 Search Search Advanced search International Study Tour Experience: Discover HSE University Application deadline: October 13 XV International Conference on Higher Education (ICHE) October 23-25 Higher Education: Efficiency and Well-being Balance International Students from Across the World International students study on-campus and remotely A wide range of scholarships and comprehensive support prev next News All news Admissions Applications for ‘Study Tour Experience’ Now Open HSE ‘Study Tour Experience’ is a project for international applicants who want to experience what it's like to be an HSE master’s student. The internship by the HSE International Admissions Office has been functioning since 2020 in two formats (offline and online) and in two languages—Russian and English. In the autumn semester of the 2024/25 academic year, the internship will take place in November. The application deadline is October 13. Research & Expertise Try Your Hand at Predicting the 2024 Nobel Prize Winner in Economics The Faculty of Economic Sciences is launching its annual prediction contest. On October 14, the Nobel Committee will announce the winners of the Sveriges Riksbank Alfred Nobel Prize in Economic Sciences live on air. You have time to prepare and explore the landscape of contemporary economic thought. What topics and areas are considered particularly important and promising at the moment? Anyone can win. Research & Expertise HSE University and Sber Researchers to Make AI More Empathetic Researchers at the HSE AI Research Centre and Sber AI Lab have developed a special system that, using large language models, will make AI more emotional when communicating with a person. Multi-agent models, which are gaining popularity, will be engaged in the synthesis of AI emotions. Research & Expertise ‘We Bring Together the Best Russian Scientists and AI Researchers at HSE University Site’ On October 25–26, 2024, HSE University’s AI and Digital Science Institute and the AI Research Centre hold the Fall into ML 2024 conference in Moscow. This year’s event will focus on the prospects in development of fundamental artificial intelligence, with SBER as its conference title partner. Education ‘Communication with Native Speakers Allowed Me to Look at the Language from a Different Perspective’ Students from HSE University–Perm completed language courses in Tianjin, China. The programme included not only classes with native speakers, but also cultural events, accommodation in a dormitory at Tianjin University, and trips to local attractions. Research & Expertise HSE Experts Take Part in the First International Workshop on Technological Sustainability of BRICS On September 19–20, Skoltech hosted the First International Workshop on Technological Sustainability of BRICS: University-Industry Partnerships, organised jointly with HSE University Human Capital Multidisciplinary Research Center. The meeting was held as part of the BRICS working group on technology foresight and science and technology studies. Education HSE Tops the Ranking of Universities Leading in Technology Entrepreneurship HSE University has taken a leading position in the university ranking prepared by the 'Expert' analytical centre. The ‘Techpred-50’ ranking evaluates the success of educational institutions in training founders of technology startups over the period from 2014 to 2023. HSE University has entered the Top-3, alongside MIPT and Moscow State University. Community ‘My Goal Was Not to Profit from the Corvids but to Develop Methods for People and Birds to Interact’ This summer, Rodion Mutsolgov from the Moscow Region enrolled in HSE University after developing a project to train birds of the corvid family to collect trash. His project was recognized as one of the best at the annual research project competition for applicants to HSE FCS. The HSE News Service interviewed the first-year student about his research discoveries and university experience. Research & Expertise Neural Network for Assessing English Language Proficiency Developed at HSE University The AI Lingua Neural Network has been collaboratively developed by the HSE University’s AI Research Centre, School of Foreign Languages, and online campus. The model has been trained on thousands of expert assessments of both oral and written texts. The system evaluates an individual's ability to communicate in English verbally and in writing. Show more Events All events 11 October Louis Vervoort to speak on 'Gettier's Problem and Quine's Epistemic Holism: A Unified Account' Starts at 18:30 null Online 14 October ANR-Lab Seminar 'Patterns of Structuring Classmate Preferences in Ethnically Mixed Classes' Starts at 15:00 null Online 23 25 October XV International Conference on Higher Education (ICHE) 25 26 October Sixth ICEF Conference on Applied Economics 25 26 October Conference on Machine Learning 'Fall into ML 2024' 28 October 9 December Course 'From a Research Idea to a Paper Draft' Online Show more Subscribe HSE University 360° Show more Alumni Careers, loyalty programmes, and mentorship International Prep Year Study Russian and complete a general preparatory course Young Scientists Early-career researchers talk about their work at HSE University University Buildings Campuses, dorms, accommodation options Careers at HSE Universty International faculty recruitment University Life News and events for HSE students and staff HSE Dormitories HSE Library On-campus libraries and remote access Pokrovka One of the most modern university complexes in Russia HSE University Strategic Development HSE International Olympiad INTO HSE: your chance to get a discount or study for free at HSE University Russian Longitudinal Monitoring Survey – HSE Nationally representative surveys since 1992 HSE Library e-resources Get access to databases and periodicals Summer Schools Joint Economic and Social Data Archive Free access to results of empirical research in social sciences Life in Moscow HSE University recommends International Student Support IQ: Commentary by HSE Experts Research and education International Faculty Support Sports at HSE University Sports clubs, gyms, contests Student Voices HSE is a school that will exceed your expectations. If you are accepted and want to pursue an academic career, do your best and study hard. High grades will open up many opportunities for you here, such as teaching and research assistant positions. Bai Xinyi (China) , Master’s programme in Economics and Economic Policy , with a focus on Behavioural Economics During my first year of the Master’s degree, I had the opportunity to meet professors and students with a highly competitive level in regional studies, Asian studies, and international relations. The programme is multidisciplinary, giving the opportunity, through courses and elective subjects, to focus your studies and converge them with your academic interests Sergio Terrón (Spain) , Master's programme in Socioeconomic and Political Development of Modern Asia I feel excited to delve into researching political regimes and conflicts among countries. I aim to achieve my goal of addressing pressing issues such as poverty, inequality, education, healthcare, and human rights violations through policy advocacy. Tajrin Rahman Tisha (Bangladesh) , Master's programme in Politics, Economics, Philosophy I researched online the best master's programmes in Russia for international students, and HSE's programmes stood out, so I decided to study here. I enjoyed my programme and had the opportunity to meet people from all over the world. Domingo Garcia (Mexico) , Master's programme in International Management I’ve already learnt much more than I expected. Everything we study is done in great detail. You do not stop after learning a theory: you need to understand how this theory is linked to the model and the empirics. Back in Ghana, I had heard about racism in Russia. However, since arriving, I’ve never felt any discrimination. Russians are very nice. What I’ve seen is totally different from what was portrayed in the media. Roosevelt Ogah (Ghana) , Master’s programme in Economics and Economic Policy HSE University in Numbers 95 % of alumni find employment within six months of graduation > 55,000 students and doctoral students > 400 international partners >5,000 instructors and researchers 47 centres of excellence prev next Contacts International Admissions inter@hse.ru admissions.hse.ru/en +7 495 531-00-59 Map of HSE Buildings International Students Support istudents.support@hse.ru istudents.hse.ru/en +7 495 772-95-90, ext. 27661 Emergency hotline: +7 (985) 040-13-55 Main campus : 11 Pokrovsky Bulvar International Faculty Recruitment iri@hse.ru iri.hse.ru +7 495 772-95-90, ext. 12669 International Faculty Support ifaculty.support@hse.ru ifaculty.hse.ru PR Office press@hse.ru pr.hse.ru/en/ +7 495 772 9567 About About Key Figures & Facts Sustainability at HSE University Faculties & Departments International Partnerships Faculty & Staff HSE Buildings Public Enquiries Studies Admissions Programme Catalogue Undergraduate Graduate Exchange Programmes Summer University Summer Schools Semester in Moscow Business Internship Research International Laboratories Research Centres Research Projects Monitoring Studies Conferences & Seminars Academic Jobs XXIV Yasin (April) International Academic Conference on Economic and Social Development Media & Resources Publications by staff HSE Journals Publishing House iq.hse.ru: commentary by HSE experts Library Economic & Social Data Archive Video ©  HSE, 1993–2024 Contacts Copyright Privacy Policy Site Map HSE Sans and HSE Slab fonts developed by the HSE Art and Design School Edit",
        "timestamp": "2024-10-11T20:33:56.839398"
    },
    {
        "header": "No_1_300924_-1.pdf",
        "text": "ПРОТОКОЛ   \n30 сентября 2024 года          Санкт -Петербург                                  № 01/2024  \n заседания комиссии по поддержке образовательных инициатив Санкт -Петербургской школы гуманитарных наук и искусств  \n  \nПрисутствовали: Т.В. Знаменская, И.Э.Кузинер, А.С. Пахомова, С.В.Чумилкин  \nПредседатель: И.Э.Кузинер  \nСекретарь: С.В.Чумилкин   \n \nПовестка дня:  \n1. Утверждение списка учебных ассистентов  \n2. Утверждение учебных ассистентов  по решению декану факультета  \n3. Установление для учебных ассистентов форм вознаграждения  \n1. Утверждение списка учебных ассистентов  \n \nПОСТАНОВИЛИ  \n1.1 утвердить список учебных ассистентов, заявки на которых  удовлетворяют пунктам 2.1 -.2.4 Правил реализации проекта «Учебный \nассистент» в НИУ ВШЭ – Санкт -Петербург  \n \n1.2 утвердить Преподавателей Санкт -Петербургской школы гуманитарных наук и искусств, организующего работу учебного ассистента и \nдисциплину, в рамках которого учебный ассистент будет задействован.  \n \n \nДепартамент иностранных языков  \n \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n1 Артемьева \nНадежда \nПавловна  Немецкий язык  1,2,3,4  3 Сивалкина  Татьяна \nАндреевна  4 10 \n2 Балакирева \nМаргарита \nЕвгеньевна  История литератур \nЕвропы и США   1,2,3  3  Погодина Алёна \nВладиславовна, \nГруппа: БФИЛЛ213  4 9 \n3 Бидерман \nОксана \nОлеговна  Английский язык для \nобщих \nкоммуникативных \nцелей. Основной курс - \n1 1, 2 1 Евсеева Алёна \nДмитриевна  2 8 \n4 Борисова \nЕлена \nАлександровна  Немецкий язык  1, 2, 3, \n4  1 Медвецкая Вероника \nВладимировна  2 9 \n5 Борисова \nЕлена \nАлександровна  Немецкий язык  1, 2, 3, \n4  1 Алпатова Елизавета \nАлексеевна  2 10 \n6 Гатауллина \nНаталья \nАнатольевна  Английский язык для \nобщих \nкоммуникативных \nцелей. Продвинутый \nкурс - 3 1,2 2 Белозеров Борис \nЮрьевич  2 7,09 \n(рейтинг)  \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n8 Гатауллина \nНаталья \nАнатольевна  Английский язык для \nобщих \nкоммуникативных \nцелей. Основной курс - \n1 1,2 2 Верещагина \nАнастасия \nВикторовна  2 7,07 \n(рейтинг)  \n9 Горина Ольга \nГригорьевна  Английский для \nспециальных \nакадемических целей. \nЭкономика \nматериальных и \nнематериальных \nактивов - 3 1, 2, 3  2 Годованюк  \nЕлизавета Сергеевна, \nГруппа: БМБ2207С  3 7 \n10 Горина Ольга \nГригорьевна  Английский язык для \nобщих \nкоммуникативных \nцелей. Основной курс -1 1, 2 1 Думанов Максим \nМихайлович, \nГруппа: БМБ2209С  3 7,11 \n(рейтинг)  \n11 Данилова \nОксана \nАлексеевна  Английский язык для \nобщих \nкоммуникативных \nцелей. Продвинутый \nкурс - 1 1,2 1  Марчук Дарья \nИгоревна  2  7,41 \n(рейтинг)  \n12 Данилова \nОксана \nАлексеевна  Английский язык для \nспециальных целей. \nАнглийский для \nюристов - 3 1,2,3  2 Бекмурзаева  Алия \nТимуровна  3  8 \n13 Данилова \nОксана \nАлексеевна  Английский язык для \nспециальных целей. \nАнглийский для \nюристов - 3 1,2,3  2  Лилия Зайцева \nАртуровна  3  9 \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n14 Данилова \nОксана \nАлексеевна  Английский язык для \nспециальных целей. \nАнглийский для \nюристов - 1 1,2  1  Банщикова Полина \nДмитриевна  2  9 \n15 Енина Анна \nДмитриевна  Английский язык для \nспециальных целей. \nДеловой английский: \nанализ и решение \nкейсов - 3 1,2,3  2 Стриженова \nАлександра \nАндреевна  3 9 \n16 Енина Анна \nДмитриевна  Английский язык для \nспециальных целей. \nДеловой английский: \nанализ и решение \nкейсов - 3 1,2,3  2 Ахмадиева Наиля \nРафаэлевна  3 9 \n17 Енина Анна \nДмитриевна  Английский язык для \nобщих \nкоммуникативных \nцелей. Продвинутый \nкурс - 1 1,2 1 Каюмова Элина \nАйнуровна  2 7,86 \n(рейтинг)  \n18 Замятина \nТатьяна \nВладимировна  Немецкий язык  1,2,3,4  1 Фазылова Вероника \nМихайловна  2 10 \n19 Замятина \nТатьяна \nВладимировна  Немецкий язык  1,2,3,4  1 Никитина Мария \nСтаниславовна  2 10 \n20 Замятина \nТатьяна \nВладимировна  Немецкий язык  1,2,3,4  2 Сивалкина Татьяна \nАндреевна  4 10 \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n21 Зелинская \nЮлия Юрьева  Немецкий язык  1, 2, 3, \n4 1 Стародубцева Мария \nАлександровна, \nГруппа: БФЛ211С   4 8 \n \n \n \n \n \n \n  \n22 Зелинская \nЮлия \nЮрьевна  Немецкий язык  1, 2, 3, \n4 1 Нечунаева  Виктория \nМихайловна, Группа: \nБФЛ233С  2 10 \n23 Зелинская \nЮлия \nЮрьевна  Немецкий язык  1, 2, 3, \n4 1 Асланова Карина \nВалерьевна, Группа: \nБФЛ231С  2 8 \n24 Знаменская \nТатьяна \nВладимировна  Английский для \nспециальных целей. \nИстория - 3 1, 2, 3  2 Кибатова  Марина \nЕвгеньевна  \nГруппа:  \nБИС211С  4 9 \n25 Знаменская \nТатьяна \nВладимировна  Английский язык. \nПодготовка к \nмеждународным \nэкзаменам  1, 2, 3  2 Шушакова Виктория \nНиколаевна, Группа: \nБИС211С  4 9 \n26 Камнева \nЛариса \nЭдуардовна  Английский для \nспециальных целей. \nОсновы SMM \nкоммуникации: \nпродвижение себя и \nпродукта в сети - 3 1, 2, 3  1 Антонова Елена \nЕвгеньевна, Группа: \nБМБ2206С  3 9 \n27 Кравченко \nСветлана \nВладимировна  Английский язык для \nобщих \nкоммуникативных 1, 2 1 Пронина Кристина \nОлеговна, Группа: \nБДЗ224С  3 8 \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \nцелей. Основной курс - \n1 \n28 Кравченко \nСветлана \nВладимировн\nа Английский язык для \nобщих \nкоммуникативных \nцелей. Основной курс \n- 1 1, 2 1 Галаганова \nЕлизавета \nАлексеевна, \nГруппа: БДЗ224С  3 7 \n29 Кучеренко \nСветлана \nНиколаевна  Английский язык для \nспециальных целей. \nЭкономика - 1 1, 2 1 Попов Платон \nДенисович, Группа: \nБМБ2201С  2 8 \n30 Молодыченко \nЕвгений \nНиколаевич  Английский язык для \nобщих \nкоммуникативных \nцелей . Основной курс \n- 1 1, 2 1 Субботина София \nВитальевна, \nГруппа: BPS233  2 8,58 \n(рейтинг)  \n31 Молодыченко \nЕвгений \nНиколаевич  Английский язык для \nобщих \nкоммуникативных \nцелей. Основной курс \n- 1 1, 2 1 Слепченко \nАнгелина \nПетровна, Группа: \nBPS222  3 8,31 \n(рейтинг)  \n32 Нужа Ирина \nВитальевна  Эффективное \nобучение \nиностранному языку  1, 2 майнор  Камская Милена \nАлександровна, \nГруппа: БКЛ211  4 10 \n33 Нужа Ирина \nВитальевна  Эффективное \nобучение \nиностранному языку  1, 2 майнор  Сатдаров \nКонстантин \nЕвгеньевич, \nГруппа: БКЛ213  4 10 \n34 Павлов \nВладимир \nВладимирови\nч Эффективная \nакадемическая \nкоммуникация для \nмагистрантов  2 Маго -лего Пустынникова \nАнастасия \nАндреевна, Группа: \nМФИНН231С  2 7,72 \n(Рейтинг)  \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n35 Пономарёва \nАнастасия \nАлексеевна  Немецкий язык  1,2,3,\n4 \nмоду\nли 1 Эртман Злата \nАлександров на \n2 10 \n36 Пономарёва \nАнастасия \nАлексеевна  Немецкий язык  1,2,3,\n4 \nмоду\nли 1 Молотилова Софья \nСемёновна  \n2 9 \n37 \nПросвиряков\nа Руслана \nИгоревна  «Английский для \nспециальных целей. \nОсновы SMM \nкоммуникации: \nпродвижение себя и \nпродукта в сети - 3» 1,2,3  2 \nКим Кристина \nМаксимовна  3 8 \n38 \nПросвиряков\nа Руслана \nИгоревна  «Английский для \nспециальных целей. \nОсновы SMM \nкоммуникации: \nпродвижение себя и \nпродукта в сети - 3» 1,2,3 2 \nПлахотина Дарья \nСергеевна  3 7 \n39 Синеокая \nНаталья \nАлексеевна  Немецкий язык  1, 2, \n3, 4 2 Амплеева \nМарианна \nОлеговна, Группа: \nБФЛ224С  3 8 \n40 Синеокая \nНаталья \nАлексеевна  Немецкий язык  1, 2, \n3, 4 3 Симонян Анна \nАндраниковна, \nГруппа: БФЛ212С  4 10 \n41 Солнцев \nСергей \nВладимирови\nч Английский язык для \nделового общения. \nПродвинутый курс - 1 1, 2 1 Перова Дарья \nРомановна, \nГруппа: БМБ2210С  2 8 \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \n42 Солнцев \nСергей \nВладимирови\nч Латинский язык  1, 2, \n3, 4 1 Хорев Тимур  \nИгоревич, Группа: \nБИС232С  2 9 \n43 Трофимова \nНэлла \nАркадьевна  Немецкий язык  1, 2, \n3, 4 2 Масленикова \nАлександра \nСергеевна, Группа: \nБФЛ222С  3 10 \n44 Трофимова \nНэлла \nАркадьевна  Немецкий язык  1, 2, \n3, 4 2 Орлова Алина \nДенисовна, Группа: \nБФЛ222С  3 9 \n45 Урсул \nНаталья \nВалерьевна  Научно -\nисследовательский \nсеминар \"Методы \nисследований в \nфинансах\"  1,2,3,\n4 \nмоду\nли 1 Данеш Пежу Сайед \nОмайр  2 8 \n46 Урсул \nНаталья \nВалерьевна  Языковая \nвариативность  3 маго -лего Анку Ворланио \nКофи, Группа: \nМФИНН232С  2 7,72 \n(рейтинг)  \n47 Урсул \nНаталья \nВалерьевна  Язык, культура и \nмежкультурная \nкоммуникация  1, 2 майнор  Садыкова Алина \nИрековна, Группа: \nБВВ222  3 10 \n48 Урсул \nНаталья \nВалерьевна  Язык, культура и \nмежкультурная \nкоммуникация  1, 2 майнор  Бабайлова \nВладислава \nВладиславовна, \nГруппа: Ю -22-2 2 10 \n49 Урсул \nНаталья \nВалерьевна  Язык, культура и \nмежкультурная \nкоммуникация  1, 2 майнор  Абдурасулов \nРауан, Группа: \nБМО221  3 10 \n50 Урсул \nНаталья \nВалерьевна  Научно -\nисследовательский \nсеминар \n\"Академическое 1, 2 1 Али Мухаммад \nСамеед, Группа: \nММЕИВ232С  2 10 \n Руководитель  \n Наименование \nдисциплины  \n Моду\nли \nдисци\nплин\nы Курс \nдисциплины  \n ФИО учебного \nассистента  \n Курс \nучеб\nного \nасси\nстен\nта Оценка УА \nпо \nдисциплин\nе \nчтение, письмо и \nпрезентация\"  \n51 Урсул \nНаталья \nВалерьевна  Научно -\nисследовательский \nсеминар \n\"Академическое \nчтение, письмо и \nпрезентация\"  1, 2 1 Чехова Анастасия  \nАнатольевна, \nГруппа: \nММЕИВ231С  2 10 \n52 Цветкова \nАлександра \nВикторовна  Английский язык для \nспециальных целей. \nДеловой английский: \nанализ и решение \nкейсов - 3 1,2,3  2 Бармышева Ксения \nДмитриевна, \nГруппа: БМБ2209С  3 9 \n53 Цветкова \nАлександра \nВикторовна  Английский язык для \nспециальных целей. \nДеловой английский: \nанализ и решение \nкейсов - 3 1,2,3  2 Капустина Алиса \nИльинична, Группа: \nБМБ2207С  3 9 \n \n \n \n \n \n \nДепартамент  истории  \n \nРуководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного \nассистента  Курс \nучебного \nассистент а Оценка УА \nпо \nдисциплине  \n1 Васильев Павел \nАндреевич  Репродуктивное \nздоровье и \nдемографическая \nполитика в России \nНового времени  3, 4 4 Рубан Евгения \nИгоревна, Группа: \nМГЛРИ231С  2 8,54 \n(рейтинг)  \n2 Васильев Павел \nАндреевич  Репродуктивное \nздоровье и \nдемографическая \nполитика в России \nНового времени  3, 4 4 Сираева Арина \nИльдаровна, \nГруппа: \nМГЛРИ231С  2 8,14 \n(рейтинг)  \n3 Васильев Павел \nАндреевич  Общество и \nздоровье в \nисторической \nперспективе  1, 2 4 Кузнецова Алиса \nАртемовна, \nГруппа: \nМГЛРИ241С  1 8,77 \n(рейтинг)  \n4 Васильев Павел \nАндреевич  История и \nантропология \nэмоций  4 1 Горбатенко Яна \nВалерьевна, \nаспирант  3 курс  8,75 \n(рейтинг)  \n5 Васильев Павел \nАндреевич  Академическое \nчтение  1, 2 1 Астаев Никита \nВячеславович, \nГруппа: БИС231С  2 10 \n6 Васильев Павел \nАндреевич  Академическое \nчтение  1, 2 1 Бережок Варвара \nИгоревна, Группа: \nБИС231С  2 9 \n \nРуководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного \nассистента  Курс \nучебного \nассистент а Оценка УА \nпо \nдисциплине  \n7 Егоров Евгений \nВитальевич  Академическое \nписьмо  1 2 Старкова \nАнастасия \nМихайловна, \nГруппа: БИС211С  4 9 \n8 Егоров Евгений \nВитальевич  Научно -\nисследовательский \nсеминар - 4 2, 3, 4  4 Шульжицкая \nМария \nНиколаевна, \nГруппа: \nМГЛРИ241С  1 10 \n9 Калеменева \nЕкатерина \nАлексеевна  Социалистический \nурбанизм в \nглобальном \nконтексте  1, 2 4 Кузнецов Максим \nАлександрович, \nГруппа: БИС201С  5 10 \n10 Кузинер Игорь \nЭдуардович  Научно -\nисследовательский \nсеминар - 2 2, 3, 4  2 Салеева Ангелина \nИгоревна, Группа: \nБИС202С  5 8 \n11 Кузинер Игорь \nЭдуардович  История в \nменяющемся мире  1, 2, 3 1 Бережок Варвара \nИгоревна, Группа: \nБИС231С  2 9 \n12 Кузинер Игорь \nЭдуардович  Глобальная \nистория в ХХ веке  3 4 Салеева Ангелина \nИгоревна, Группа: \nБИС202С  5 9 \n13 Кузинер Игорь \nЭдуардович  Глобальная \nистория в ХХ веке  3 4 Флигинская  \nЕкатерина \nДмитриевна, \nГруппа: БИС202С  5 9 \n \nРуководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного \nассистента  Курс \nучебного \nассистент а Оценка УА \nпо \nдисциплине  \n14 Кузинер Игорь \nЭдуардович  Историческая \nгеография  3, 4 1 Русакова Зоя \nДмитриевна, \nГруппа: БИС212С  4 10 \n15 Платонова Евгения \nСергеевна  Основы \nроссийской \nгосударственности  1 1 Синицына Вера \nРомановна, \nГруппа: БИС232С  2 9 \n16 Платонова Евгения \nСергеевна  Основы \nроссийской \nгосударственности  1 1 Цатинян Марк \nАрсенович, \nГруппа: БИС232С  2 9 \n17 Старун Мария \nИгоревна  История правовых, \nполитических и \nсоциальных \nучений  3, 4 3 Старкова \nАнастасия \nМихайловна, \nГруппа: БИС211С  4 9 \n18 Старун Мария \nИгоревна  История правовых, \nполитических и \nсоциальных \nучений  3, 4 3 Панахова Диана \nЯшаровна, \nГруппа: БИС211С  4 7 \n19 Старун Мария \nИгоревна  Политическая \nистория \nзарубежных стран  1, 2 1 Фейгина  Татьяна \nАлександровна, \nГруппа: BPS231  2 9 \n20 Старун Мария \nИгоревна  Социальная \nистория магии  2 2 Давутова Алсу \nРафаиловна, \nГруппа: БИС221С  3 8 \n \nРуководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного \nассистента  Курс \nучебного \nассистент а Оценка УА \nпо \nдисциплине  \n21 Старун Мария \nИгоревна  Научно -\nисследовательский \nсеминар 1  1, 2, 3, 4  1 Пермякова \nПолина \nВасильевна, \nГруппа: БИС222С  3 9 \n22 Чунихин Кирилл \nАлександрович  История искусства \nи визуальной \nкультуры  1, 2 3 Старковская \nАнастасия \nПавловна, Группа: \nБИС211С  4 9 \n \nДепартамент филологии  \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n1 Блинова Ольга \nВладимировна  Введение в \nязыкознание  1, 2, 3, 4  1 Захарина Елизавета Васильевна, \nГруппа: БФЛ233С  2 9 \n2 Блинова Ольга \nВладимировна  Введение в \nязыкознание  1, 2, 3, 4  1 Славко Полина Андреевна, Группа: \nБФЛ232С  2 8 \n3 Блинова Ольга \nВладимировна  Введение в \nязыкознание  1, 2, 3, 4  1 Юсупова Амалия Рауфовна, Группа: \nБФЛ233С  2 10 \n4 Бодрова Алина \nСергеевна  Академическое письмо \n(на русском языке)  1, 2 1 Ефремова Дарья Андреевна, Группа: \nБФЛ233С  2 9 \n5 Бодрова Алина \nСергеевна  История новой русской \nлитературы (19 -20 вв.)  1, 2, 3, 4  3 Моисеева Мария Владимировна, \nГруппа: МРЛИП231С  2 10 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n6 Бодрова Алина \nСергеевна  Ключевые тексты \nмировой литературы  1, 2, 3, 4  1 Грищенкова Ева Вячеславовна, \nГруппа: БФЛ232С  2 10 \n7 Бодрова Алина \nСергеевна  Академическое письмо \n(на русском языке)  1, 2 1 Орос  Камилла Романовна, Группа: \nБФЛ231С  2 10 \n9 Горошкова Рената \nРишатовна  История искусства и \nлитературы  1, 2 1 Елкина Екатерина Александровна, \nГруппа: БИС221С  3 8 \n10 Горошкова Рената \nРишатовна  Сравнительные \nаспекты изучения \nлитературы и \nискусства  3, 4 2 Кирочкина Полина Константиновна, \nГруппа: БФЛ224С  3 9 \n11 Горошкова Рената \nРишатовна  История искусства и \nлитературы  1, 2 1 Смирнова Яна Вадимовна, Группа: \nБИС232С  2 10 \n12 Ермакова Лия \nЛеонидовна  Ключевые тексты \nмировой литературы  1, 2, 3, 4  1 Зильберт  Виктория Максовна, Группа: \nБФЛ232С  2 10 \n13 Ермакова Лия \nЛеонидовна  Ключевые тексты \nмировой литературы  1, 2, 3, 4  1 Юречко Тамара Алексеевна, Группа: \nБФЛ232С  2 8 \n14 Казарцев Евгений \nВячеславович  Стих и проза в \nконтексте цифровых \nгуманитарных наук  2, 3 модули  1 курс  Кириченко Никита Валерьевич  2 9 \n15 Казарцев Евгений \nВячеславович  Стих и проза в \nконтексте цифровых \nгуманитарных наук  2, 3 модули  1 курс  Сабиров Дмитрий Викторович  3 10 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n16 Казарцев  Евгений \nВячеславович  Стих и проза в \nконтексте цифровых \nгуманитарных наук  2, 3 модули  1 курс  Бархатова Анастасия Алексеевна  3 9 \n17 Калугин Дмитрий \nЯковлевич  Формы знания о \nчеловеке: от \nантичности до \nсовременности  1, 2 4 Русакова Зоя Дмитриевна, Группа: \nБИС212С  4 9 \n18 Кирина Маргарита \nАлександровна  Цифровая грамотность  1, 2 1 Маторная Мария Артемовна, Группа: \nБИС232С  2 10 \n19 Кирина Маргарита \nАлександровна  Цифровая грамотность  1, 2 1 Туякова Даяна Айдынгалеевна, \nГруппа: БИС232С  2 10 \n20 Кирина Маргарита \nАлександровна  Цифровые методы для \nгуманитариев  1 3 Иванова Екатерина Андреевна, \nГруппа: БФЛ212С  4 10 \n21 Кирина Маргарита \nАлександровна  Цифровые методы для \nгуманитариев  1 3 Коляда Дарья Станиславовна, Группа: \nБФЛ212С  4 9 \n22 Кирина Маргарита \nАлександровна  Цифровые методы для \nгуманитариев  1 3 Лукьянчикова Алиса Сергеевна, \nГруппа: БФЛ213С  4 10 \n23 Кирина Маргарита \nАлександровна  Цифровые методы для \nгуманитариев  1 3 Степанец Ксения Сергеевна, Группа: \nБФЛ212С  4 9 \n24 Кирина Маргарита \nАлександровна  Цифровая грамотность  1, 2 1 Грищенкова  Ева Вячеславовна, \nГруппа: БФЛ232С  2 9 \n25 Кирина Маргарита \nАлександровна  Цифровая грамотность  1, 2 1 Фазылова Вероника Михайловна, \nГруппа: БФЛ232С  2 10 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n26 Кирина Маргарита \nАлександровна  Цифровая грамотность  1, 2 1 Цыганкова Александра Вячеславовна, \nГруппа: БФЛ233С  2 9 \n27 Кирина Маргарита \nАлександровна  Основы \nпрограммирования на \nPython  3 2 Деборина Виктория Дмитриевна, \nГруппа: БФЛ222С  3 9 \n28 Кирина Маргарита \nАлександровна  Основы \nпрограммирования на \nPython  3 2 Кушерекин  Александр \nАлександрович, Группа: БИС221С  3 10 \n29 Кирина Маргарита \nАлександровна  Основы \nпрограммирования на \nPython  3 2 Стельмак Елизавета Алексеевна, \nГруппа: БФЛ223С  3 10 \n30 Кирина Маргарита \nАлександровна  Анализ данных  2 3 Амирова Екатерина Дмитриевна, \nГруппа: БФЛ211С  4 9 \n31 Кирина Маргарита \nАлександровна  Анализ данных  2 3 Пермякова Полина Васильевна, \nГруппа: БИС222С  3 10 \n32 Кирина Маргарита \nАлександровна  Анализ данных  2 3 Урих Алиса Евгеньевна, Группа: \nБФЛ212С  4 10 \n33 Кирина Маргарита \nАлександровна  Анализ данных  2 3 Фролова Софья Вячеславовна, \nГруппа: БИС222С  3 9 \n Кирина Маргарита \nАлександровна  Анализ данных в \nExcel/Python  1, 2 3 Столяров Александр Григорьевич, \nГруппа: БИС222С  3 10 \n34 Кирина Маргарита \nАлександровна  Анализ данных в \nExcel/Python  1, 2 3 Чеповецкая София Вадимовна, \nГруппа: БФЛ211С  4 10 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n35 Князев Михаил \nЮрьевич  Теоретические \nподходы и \nнаправления \nсовременной \nлингвистики  1, 2, 3, 4  3 Родионов Руслан Андреевич, Группа: \nБФЛ211С  4 10  \n36 Князев Михаил \nЮрьевич  Теоретические \nподходы и \nнаправления \nсовременной \nлингвистики  1, 2, 3, 4  3 Стародубцева Мария Александровна, \nГруппа: БФЛ211С  4 9  \n37 Козлов Дмитрий \nСергеевич  Ключевые тексты \nмировой литературы  1,2,3,4  1 курс  Фадеева Екатерина Сергеевна  2 курс  \n9 \n38 Пахомова \nАлександра \nСергеевна  Теория и типология \nмирового фольклора  1, 2 2 Макарова Анастасия Александровна, \nГруппа: БФЛ221С  3 10 \n39 Пахомова \nАлександра \nСергеевна  Академическое письмо \n(на русском языке)  1, 2 1 Кириченко Никита Валерьевич, \nГруппа: БФЛ232С  2 9 \n40 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nГромова Елена Алексеевна  3 9 \n41 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nТанага  Ирина Романовна  2 9 \n42 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nСолодуха Валерия Алексеевна  2 9 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n43 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nНаумова Виолетта Владимировна  3 8 \n44 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nХарабажиу Александра Андреевна  2 8 \n45 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nЮрова Алёна Николаевна  2 7 \n46 Попова Татьяна \nИвановна  Цифровая грамотность  1, 2 модули  1 \nЛукьянов Рустам Зарифджонович  2 7 \n47 Попова Татьяна \nИвановна  Введение в \nязыкознание  1,2 модули  2 Амплеева Марианна Олеговна  3 \n9 \n48 Попова Татьяна \nИвановна  Введение в \nязыкознание  1,2 модули  2 Маркович Ольга Игоревна  3 \n9 \n49 Попова Татьяна \nИвановна  Введение в \nязыкознание  1,2 модули  2 Каличева Варвара Максимовна  3 \n9 \n50 Рудалева Екатерина \nАндреевна  Основы \nпрограммирования на \nPython  1, 2 модули  2 \nАмплеева Марианна Олеговна  3 10 \n51 Рудалева Екатерина \nАндреевна  Основы \nпрограммирования на \nPython  1, 2 модули  2 \nЕрмолчева  Анна Сергеевна  3 10 \n52 Рудалева Екатерина \nАндреевна  Основы \nпрограммирования на \nPython  1, 2 модули  2 \nЕмбулаева Александра Александровна  3 10 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n53 Рудалева Екатерина \nАндреевна  Основы \nпрограммирования на \nPython  1, 2 модули  2 \nЖаркова Елизавета Игоревна  3 10 \n54 Рудалева Екатерина \nАндреевна  Основы \nпрограммирования на \nPython  1, 2 модули  2 \nБыкова Ульяна Григорьевна  3 10 \n55 Фирсанова \nВиктория Игоревна  Научно -\nисследовательский \nсеминар \"Основы \nсоздания диалоговых \nсистем\"  2-3 2 Савченко Егор Алексеевич  3 8 \n56 Шерстинова Татьяна \nЮрьевна  Количественные \nметоды анализа \nлитературного текста  1 2 Быкова Ульяна Григорьевна, Группа: \nБФЛ221С  3 9 \n57 Шерстинова Татьяна \nЮрьевна  Количественные \nметоды анализа \nлитературного текста  1 2 Громова Елена Алексеевна, Группа: \nБФЛ221С  3 10 \n58 Шерстинова Татьяна \nЮрьевна  Количественные \nметоды анализа \nлитературного текста  1 2 Наумова Виолетта Владимировна, \nГруппа: БФЛ223С  3 9 \n59 Шерстинова Татьяна \nЮрьевна  Количественные \nметоды анализа \nлитературного текста  1 2 Новосельцева Алёна Олеговна, \nГруппа: БФЛ221С  3 9 \n60 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nОрос Камилла Романовна  2 8 \n Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного ассистента  Курс \nучебного \nассистента  Оценка УА \nпо \nдисциплине  \n61 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nБородаенко  Ева Евгеньевна  2 8 \n62 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nТуркина Устина Сергеевна  2 8 \n63 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nСирая Мария Александровна  2 8 \n64 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nМамедова София Байрамовна  2 8 \n65 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nКурносова Арина Дмитриевна  2 7 \n66 Шклярук Екатерина \nЯрославовна  Цифровая грамотность  1, 2 модули  1 \nОгий Мария  2 7 \n        \n \n2. Утверждение учебных ассистентов  по решению декану факультета . \nПОСТАНОВИЛИ : \n \nДопустить до исполнения обязанностей учебн ых ассистент ов студентов,  заявки  которых не удовлетворяли пунктам 2.1 -2.4  Правил \nреализации проекта «Учебный ассистент» в НИУ ВШЭ – Санкт -Петербург , однако были поддержаны решением декана факультета \nСелиным А.А  (на основании  письменных обращени й руководителей  этих учебных ассистентов)    с уточнением, что данные заявки \nмогут претендовать только на неденежные вознаграждения.  \n3. Установление для учебных ассистентов форм вознаграждения  \nПОСТАНОВИЛИ  \nвследствие отсутствия у Комиссии решения финансового комитета НИУ ВШЭ - Санкт Петербург об объеме финансирования учебных \nассистентов, выделенного Факультету Санкт -Петербургская школа  гуманитарных наук и искусств, перенести рассмотрение вопроса  об \nутверждении финансовых и иных формах вознаграждения для учебных ассистентов на срок не позднее 5 рабочих дней с момента \nпоступления в Комиссию информации о решении Финансового комитета.  \n \nПредседатель комиссии                                   к.и.н., ст. преп. И.Э.Кузинер  \n  \nСекретарь                                                             ст. преп. С.В. Чумилкин   Руководитель  Наименование \nдисциплины  Модули \nдисциплины  Курс \nдисциплины  ФИО учебного \nассистента  Курс \nучебного \nассистента  Оценка УА по дисциплине  \n1 Гатауллина Наталья \nАнатольевна  Английский язык \nдля общих \nкоммуникативных \nцелей. \nПродвинутый курс \n- 3 1,2,3  2 Барсегян Анна \nАслановна  2 6,42 (рейтинг)   \n2 Горина Ольга \nГригорьевна  Английски й язык \nдля \nкоммуникативны\nх целей\", \nОсновной курс -\n1. 1,2 1 Ускова  \nАлександра  \nДмитриевна  2 6,83 \n",
        "timestamp": "2024-10-11T20:35:20.760529"
    },
    {
        "header": "python_1.pdf",
        "text": "Конспект: Числа и строки в Python.\nКонструкция IF.\nВ.И. Фирсанова\n24 сентября 2024\n1 Числа\n1.1 Комплексные числа: complex\nКомплексные числа представляются в виде a+bi, где a— вещественная\nчасть, а bi— мнимая часть, которая состоит из вещественного числа bи\nмнимой единицы i, равной√−1):\nx = 3+5j\ny = 5j\nprint ( type (x)) # <class ’complex ’>\nprint ( type (y)) # <class ’complex ’>\n1.2 Числа с плавающей точкой: float\nЧисла с плавающей точкой соответствуют вещественным числам, однако\nне являются ими из-за особенностей представления чисел в памяти вычис-\nлительного устройства:\na = 0.1 + 0.1 + 0.1\nb = 0.3\nprint (a == b) # False\nПочему 0.1 + 0.1 + 0.1не равно 0.3? Вещественные числа состоят из двух\nчастей – мантиссы и порядка. Мантисса – это целое число, например, 3.\nПорядок – это 10 в n-ной степени. Порядок задает количество знаков после\nзапятой. Чем больше памяти в битах выделяется на кодирование мантиссы\nи порядка, тем ближе наши числа к вещественным числам.\n1.3 Целые числа: int\nЦелые числа не имеют дробной части. Преобразование к целочисленному\nвиду дает округление:\n1\nx = 42\nprint ( type (x)) # <class ’int ’>\ny = 42.1\nprint (int (y)) # 42\n1.4 Булева переменная\nБулев тип данных имеет два значения: TrueиFalse. В Python этот тип\nследует из логических выражений, например and,or,not:\n3 == 3 and 3 == 3 # True\n3 == 3 or 3 == 2 # True\nnot isinstance (3, int ) # False\n4 not in [1, 2, 3] # True\n3 > 1 # True\n0 == 0 # True\n1 != 1 # False\n2 <= 1 # False\n2 Строки\nСтрока — это последовательность символов, и она является итерируемым\nобъектом:\n\"Hello , World \"\n’Hello , World ’\nСтрокимогутсодержатьспециальныесимволы,например,переносстро-\nки:\n’Hello , World \\nHello , World ’\nДля вывода строки используем функцию print():\nprint (’Hello , World ’) # Hello , World\n2.1 Форматирование строк: f-strings\nИспользование f-строк позволяет вставлять значения переменных в строку:\nname = \" John \"\nprint (f’Hello , { name }’) # Hello , John\n2\n2.2 Основные функции для работы со строками\n•Длина строки : Функция len()возвращает количество символов в\nстроке.\ns = \"Hello, World!\"\nprint(len(s)) # 13\n•Приведение к верхнему и нижнему регистру :\ns = \"Hello\"\nprint(s.upper()) # HELLO\nprint(s.lower()) # hello\n•Капитализация строки :\ns = \"hello\"\nprint(s.capitalize()) # Hello\n•Разбиение строки :\ns = \"one, two, three\"\nprint(s.split(’,’)) # [’one’, ’two’, ’three’]\n•Удаление пробелов :\ns = \" hello \"\nprint(s.strip()) # hello\n•Замена подстроки :\ns = \"this is an apple\"\nprint(s.replace(\"apple\", \"orange\")) # this is an orange\n•Регулярные выражения :\nimport re\ntext = \"Contact us at info@example.com\"\ncleaned_text = re.sub(r’\\S+@\\S+’, ’’, text)\nprint(cleaned_text) # Contact us at\n3\n3 Условные операторы\nУсловные операторы используются для выполнения кода в зависимости от\nистинности выражения:\nvar = 3\nif var == 3:\nvar += 1\nprint (var ) # 4\nОператор elseиспользуетсядляобработкислучая,когдаусловие ifложно:\nif var == 3:\nvar += 1\nelse :\nvar = 3\nОператор elifиспользуется для проверки дополнительных условий:\nif var == 3:\nvar += 1\nelif var == 4:\nvar += 2\nelse :\nvar = 3\n4\n",
        "timestamp": "2024-10-11T20:36:27.562547"
    },
    {
        "header": "python_1.pdf",
        "text": "Конспект: Числа и строки в Python.\nКонструкция IF.\nВ.И. Фирсанова\n24 сентября 2024\n1 Числа\n1.1 Комплексные числа: complex\nКомплексные числа представляются в виде a+bi, где a— вещественная\nчасть, а bi— мнимая часть, которая состоит из вещественного числа bи\nмнимой единицы i, равной√−1):\nx = 3+5j\ny = 5j\nprint ( type (x)) # <class ’complex ’>\nprint ( type (y)) # <class ’complex ’>\n1.2 Числа с плавающей точкой: float\nЧисла с плавающей точкой соответствуют вещественным числам, однако\nне являются ими из-за особенностей представления чисел в памяти вычис-\nлительного устройства:\na = 0.1 + 0.1 + 0.1\nb = 0.3\nprint (a == b) # False\nПочему 0.1 + 0.1 + 0.1не равно 0.3? Вещественные числа состоят из двух\nчастей – мантиссы и порядка. Мантисса – это целое число, например, 3.\nПорядок – это 10 в n-ной степени. Порядок задает количество знаков после\nзапятой. Чем больше памяти в битах выделяется на кодирование мантиссы\nи порядка, тем ближе наши числа к вещественным числам.\n1.3 Целые числа: int\nЦелые числа не имеют дробной части. Преобразование к целочисленному\nвиду дает округление:\n1\nx = 42\nprint ( type (x)) # <class ’int ’>\ny = 42.1\nprint (int (y)) # 42\n1.4 Булева переменная\nБулев тип данных имеет два значения: TrueиFalse. В Python этот тип\nследует из логических выражений, например and,or,not:\n3 == 3 and 3 == 3 # True\n3 == 3 or 3 == 2 # True\nnot isinstance (3, int ) # False\n4 not in [1, 2, 3] # True\n3 > 1 # True\n0 == 0 # True\n1 != 1 # False\n2 <= 1 # False\n2 Строки\nСтрока — это последовательность символов, и она является итерируемым\nобъектом:\n\"Hello , World \"\n’Hello , World ’\nСтрокимогутсодержатьспециальныесимволы,например,переносстро-\nки:\n’Hello , World \\nHello , World ’\nДля вывода строки используем функцию print():\nprint (’Hello , World ’) # Hello , World\n2.1 Форматирование строк: f-strings\nИспользование f-строк позволяет вставлять значения переменных в строку:\nname = \" John \"\nprint (f’Hello , { name }’) # Hello , John\n2\n2.2 Основные функции для работы со строками\n•Длина строки : Функция len()возвращает количество символов в\nстроке.\ns = \"Hello, World!\"\nprint(len(s)) # 13\n•Приведение к верхнему и нижнему регистру :\ns = \"Hello\"\nprint(s.upper()) # HELLO\nprint(s.lower()) # hello\n•Капитализация строки :\ns = \"hello\"\nprint(s.capitalize()) # Hello\n•Разбиение строки :\ns = \"one, two, three\"\nprint(s.split(’,’)) # [’one’, ’two’, ’three’]\n•Удаление пробелов :\ns = \" hello \"\nprint(s.strip()) # hello\n•Замена подстроки :\ns = \"this is an apple\"\nprint(s.replace(\"apple\", \"orange\")) # this is an orange\n•Регулярные выражения :\nimport re\ntext = \"Contact us at info@example.com\"\ncleaned_text = re.sub(r’\\S+@\\S+’, ’’, text)\nprint(cleaned_text) # Contact us at\n3\n3 Условные операторы\nУсловные операторы используются для выполнения кода в зависимости от\nистинности выражения:\nvar = 3\nif var == 3:\nvar += 1\nprint (var ) # 4\nОператор elseиспользуетсядляобработкислучая,когдаусловие ifложно:\nif var == 3:\nvar += 1\nelse :\nvar = 3\nОператор elifиспользуется для проверки дополнительных условий:\nif var == 3:\nvar += 1\nelif var == 4:\nvar += 2\nelse :\nvar = 3\n4\n",
        "timestamp": "2024-10-12T13:09:48.736013"
    }
]